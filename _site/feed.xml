<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shihanmax</title>
    <description>Shihanmax's blog
</description>
    <link>http://localhost:4000//</link>
    <atom:link href="http://localhost:4000//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 29 Mar 2021 17:15:39 +0800</pubDate>
    <lastBuildDate>Mon, 29 Mar 2021 17:15:39 +0800</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      <item>
        <title>XGBoost理解</title>
        <description>&lt;p&gt;&lt;strong&gt;本文正在整理中…🚧&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;XGBoost（eXtreme Gradient Boosting）是GBDT的一种高效的工程实现，在数据竞赛中应用十分广泛。&lt;/p&gt;

&lt;p&gt;下文从决策树的定义开始，介绍决策树的分裂指标、决策树在boosting算法中的应用BDT、引入残差信息的Gradient boosting算法等，最后，介绍集成了多种高效算法的XGBoost的工程实现。&lt;/p&gt;

&lt;h2 id=&quot;一决策树&quot;&gt;一、决策树&lt;/h2&gt;

&lt;p&gt;决策树是一种描述对实例进行分类的属性结构，由节点和有向边组成，其中，节点分为内部节点和叶子结点，内部节点表示特征或属性，叶子结点表示一个类。&lt;/p&gt;

&lt;p&gt;从根节点开始，对样本的某一个特征进行测试，根据结果，将样本划分到其若干个子节点中，其中每个子节点均对应该特征的一个取值；针对每一个子节点，继续选取一个特征重复执行上述过程，直到将实例划分到叶节点所对应的类别当中。&lt;/p&gt;

&lt;p&gt;在上述描述过程中，有一个重要的点是，如何选择一个最好的特征，并使用其进行样本的划分？&lt;/p&gt;

&lt;p&gt;直观上考虑，如果划分后的子集拥有更高的“纯度”，则表示该特征是一个好的特征。所谓纯度是指，划分后的子样本集合所对应的类别应尽可能一致，极端考虑，假设我们选择了一个特征，在使用此特征进行划分后，所有的子集合中，样本的类别几乎一致，则可以认为这个特征是一个非常强的特征。&lt;/p&gt;

&lt;p&gt;在决策树实现过程中，一般使用三个指标衡量分类纯度：信息增益、信息增益比、基尼指数。首先回顾一下信息论中几个基础的概念：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;熵（Entropy）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设$X$是随机变量，$P(X=x_i)=p_i,i=1,2,…,n$，则$X$的熵定义为：&lt;/p&gt;

\[H(X)=-\sum_\limits{i=1}^{n}{p_i}\log{p_i}\]

&lt;p&gt;可以看出，$X$的熵的取值仅与$X$的分布有关，与$X$的取值无关，所以这里$H(X)$也可以写作$H(p)$。上式中的对数以$2$为底时，熵的单位为$bit$；以$e$为底时对应的单位为$nat$。&lt;/p&gt;

&lt;p&gt;熵可以用来衡量随机变量的不确定性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;条件熵&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;条件熵$H(Y\mid X)=\sum_\limits{i=1}^{n}{p_i}H(Y\mid X=x_i)$，其中，$p_i=P(X=x_i),i=1,2,…,n$。&lt;/p&gt;

&lt;p&gt;条件熵$H(Y\mid X)$表示，在已知随机变量$X$时，随机变量$Y$的不确定性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息增益（互信息）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;信息增益定义为：$MI(Y,X)=H(Y)-H(Y\mid X)$，表示“得知$X$的信息，而使$X$的&lt;strong&gt;不确定性&lt;/strong&gt;减少的程度”。&lt;/p&gt;

&lt;p&gt;在决策树的特征选择过程中，使用特征$A$对数据集$D$进行分割，所带来的信息增益可以表示为：$g(D,A)=MI(D,A)=H(D)-H(D\mid A)$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息增益比&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有以上定义可知，通过计算信息增益来进行数据分割时，会偏向取值较多的特征的问题，针对此问题，使用信息增益比来进行修正：&lt;/p&gt;

&lt;p&gt;$g_{R}(D,A)=\frac{g(D,A)}{H_{A}(D)}$，其中$H_A(D)=-\sum_\limits{i=1}^{n}{\frac{\mid D_i\mid}{\mid D\mid}}\log{\frac{\mid D_i\mid}{\mid D\mid}}$，即计算数据集$D$的熵时，特征$A$的贡献。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基尼指数Gini Index&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在分类问题中，假设有$k$个类别，样本属第$k$类的概率为$p_k$，则概率分布的基尼指数定义为：&lt;/p&gt;

\[Gini(p)=\sum_\limits{k=1}^{K}p_k(1-p_k)=1-\sum_\limits{k=1}^{K}p_k^2\]

&lt;p&gt;则数据集$D$的基尼指数为：&lt;/p&gt;

\[Gini(D)=1-\sum_\limits{k=1}^{K}\frac{\mid C_k\mid}{\mid D \mid}\]

&lt;p&gt;其中，$C_k$表示第$k$类样本子集的大小。&lt;/p&gt;

&lt;p&gt;假设有特征A，根据特征$A$是否满足特定条件，将数据集划分为两部分：$D_1,D_2$，则可以定义：给定特征$A$的条件下，样本集合$D$的基尼指数$Gini(D,A)$（即给定特征$A$后，样本集合$D$的不确定性减少的程度）：&lt;/p&gt;

\[Gini(D,A)=\frac{\mid D_1\mid}{\mid D \mid}Gini(D_1)+\frac{\mid D_2\mid}{\mid D \mid}Gini(D_2)\]

&lt;p&gt;在决策树的构建阶段，我们便可以在进行最优特征选择时，遍历所有的特征，然后计算出其纯度指标（信息增益、信息增益比、基尼指数），然后选出一个指标最高的特征，并根据该特征的取值将样本集合分裂。&lt;/p&gt;

&lt;p&gt;常用的决策树算法有ID3算法、C4.5算法和CART算法，其中ID3算法使用信息增益进行特征选择；C4.5算法进行了改进，使用信息增益比进行特征选择；对于分类树，CART算法使用基尼指数最小化准则，对于回归树，使用平方误差最小化准则。&lt;/p&gt;

&lt;h2 id=&quot;二boosting&quot;&gt;二、Boosting&lt;/h2&gt;

&lt;p&gt;Boosting是集成学习思想的一种（另一个是Bagging，指并列地训练多个基模型，并通过投票（分类问题）或平均（回归问题）的方式计算得到最终的集成结果）。&lt;/p&gt;

&lt;p&gt;与Bagging的可并行不同，Boosting算法的执行流程是串行的，即后面的模型的训练依赖前面的模型的预测结果。典型的算法有Adaboost、GBDT等。下面简单介绍这两类算法。&lt;/p&gt;

&lt;h3 id=&quot;21-adaboost&quot;&gt;2.1 Adaboost&lt;/h3&gt;

&lt;p&gt;Adaboost算法（Adaptive Boosting，自适应增强）是boosting算法的代表，其特点是通过迭代训练一系列基分类器，在每次迭代过程中，提高被前一个分类器分错的样本的权重，降低被前一个分类器分对的样本的权重。最后，Adaboost算法将基分类器进行加权线性组合，每个基分类器都有一个权重，分类误差越小的基分类器，其权重越高，否则权重越低。&lt;/p&gt;

&lt;p&gt;Adaboost的执行流程简述如下：&lt;/p&gt;

&lt;p&gt;首先，初始化数据集为等权重。接着，依次迭代训练$M$个基模型$G_1,G_2,…,G_M$，针对模型$G_m$，执行以下四步：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;使用带权的数据训练$G_m$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;计算$G_m$在数据集上的带权分类误差率&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;通过此误差率计算分类器的权重&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;通过带权基模型$G_m$的预测结果，更新训练数据的权重&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在$M$个基模型训练完成后，每个基模型均有一个权重，使用该权重对一系列基模型进行加权组合，即可得到最终的分类器。&lt;/p&gt;

&lt;h3 id=&quot;22-gbdt&quot;&gt;2.2 GBDT&lt;/h3&gt;

&lt;p&gt;GBDT全称是Gradient Boost Desision Tree，即梯度提升决策树。与Adaboost不同的是，GBDT的每次迭代目标是减小之前模型的残差，在残差减小的方向（负梯度方向）建立一个新的模型。&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;假设样本$[(1,2,3), 4]$，其中$(1,2,3)$是样本特征，$4$是样本标签&lt;/p&gt;

  &lt;p&gt;假设模型$m_i$在上述样本上的预测结果是$3.6$&lt;/p&gt;

  &lt;p&gt;则模型$m_{i+1}$的拟合目标就变为：$[(1,2,3), 0.4]$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;按上述方式得到一系列基模型后，GBDT的预测值就是样本在所有基模型上的结果的&lt;strong&gt;加和&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在回归任务中，每一次迭代中对每一个样本都有一个预测值，损失函数使用MSE（均方误差损失）：$l(y_i,\hat{y_i})=\frac{1}{2}(y_i-\hat{y_i})^2$，对损失计算梯度取负：$-[\frac{\partial l(y_i,\hat{y_i})}{\partial \hat{y_i}}]=(y_i-\hat{y_i})$。&lt;/p&gt;

&lt;p&gt;由上述结果可知，当损失函数使用MSE时，每一次拟合的值就是基模型的真实值减预测值，也即“残差”。&lt;/p&gt;

&lt;h2 id=&quot;三xgboost&quot;&gt;三、XGBoost&lt;/h2&gt;

&lt;p&gt;XGBoost是一个高效、灵活、可移植的分布式梯度提升工具包。是一种基于梯度提升框架的并行化的提升树实现方案。&lt;/p&gt;

&lt;p&gt;XGBoost的思想是，不断地在训练过程中添加树，利用特征分裂来生长一棵树，添加树的过程就是拟合一个新函数的过程，这个新函数的拟合对象是上一次预测结果的残差。&lt;/p&gt;

\[\hat{y}=\phi(x_i)=\sum_\limits{k=1}^Kf_k(x_i)\]

&lt;p&gt;训练完成后得到$K$棵树，针对一个样本，该样本的特征在$K$棵树上会落到$K$个叶子结点上，得到$K$个预测分数，将这些分数相加，就能得到该样本的预测值。&lt;/p&gt;

&lt;h3 id=&quot;31-xgboost的目标函数和误差&quot;&gt;3.1 XGBoost的目标函数和误差&lt;/h3&gt;

&lt;p&gt;将XGBoost的误差可以简写如下：&lt;/p&gt;

\[L(\phi)=\sum_\limits{i}l(\hat{y_i}-y_i)+\sum_\limits{t}\Omega(f_t)\]

&lt;p&gt;损失函数分为两部分，第一部分为误差函数，误差函数反映了当前模型对数据的拟合程度，其中$y_i$表示第$i$个样本的真实值，$\hat{y_i}$是所有基模型的输出累加；第二部分为正则化项，正则化项定义了模型的复杂度。&lt;/p&gt;

&lt;h4 id=&quot;311-误差函数&quot;&gt;3.1.1 误差函数&lt;/h4&gt;

&lt;p&gt;训练过程中，第$t$轮的模型预测值$\hat{y}^{(t)}=\hat{y}^{(t-1)}+\epsilon f_t(x_i)$，其中$\epsilon$为缩减因子（shrinkage），是为了防止过拟合而设置的，一般取$0.1$（为简单起见，以下推导略去$\epsilon$）。&lt;/p&gt;

&lt;p&gt;误差函数可以记为：$l(y_i,\hat{y}^{(t-1)},f_t(x_i))$，第$t$轮训练的目标是学习函数$f_t$，至此，XGBoost的目标函数$Obj^{(t)}$可以写为：&lt;/p&gt;

\[Obj^{(t)}=\sum\limits_{i=1}^n(l(y_i,\hat{y}^{(t-1)},f_t(x_i))   +  \Omega(f_t))   +constant\]

&lt;p&gt;上面提到，当损失函数$l(\cdot)$为MSE时，我们可以推导出，损失函数的负梯度方向即是残差，那么，当损失函数是其他形式的函数呢？&lt;/p&gt;

&lt;p&gt;XGBoost提出，对于其他形式的损失函数，则使用一个二次函数来近似，这里使用泰勒展开的方式。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;回顾泰勒定理：&lt;/p&gt;

  &lt;p&gt;设有在$a$点所在区间上$n+1$阶可导的函数$f(x)$，则对这个区间上的任意$x$，都有如下泰勒展开形式：&lt;/p&gt;

\[f(x)=f(a)+\frac{f'(a)}{1!}(x-a) +    \frac{f^{(2)}(a)}{2!}(x-a)^2+\cdot \cdot \cdot +   \frac{f^{(n)}(a)}{n!}(x-a)^n + R_n(x)\]

  &lt;p&gt;其中，$R_n(x)$为余项，是$(x-a)^n$的高阶无穷小。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在XGBoost中，对损失函数进行了二阶泰勒展开：&lt;/p&gt;

\[f(x+\Delta x) \simeq f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}\]

&lt;p&gt;定义$g_{i}=\partial_{\hat{y}^{(t-1)}} l\left(y_{i}, \hat{y}^{(t-1)}\right), \quad h_{i}=\partial_{\hat{y}^{(t-1)}}^{2}l\left(y_{i}, \hat{y}^{(t-1)}\right)$&lt;/p&gt;

&lt;p&gt;将$l(y_i,c+f_t(x_i))$中的$\hat{y_i}^{(t-1)}$看作二阶泰勒展开式中的$x$；将$f_t(x_i)$看作展开式中的$\Delta x$，则目标函数可以近似写为：&lt;/p&gt;

\[Obj^{(t)} \simeq \sum_{i=1}^{n}\left[l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right)+\text { constant }\]

&lt;p&gt;在上式中，$l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)$为样本的真实标签和第$t-1$次预测的残差，是一个已知的数值，不影响第$t$轮的优化，常数项也可以移除，因此，目标函数可以重写为：&lt;/p&gt;

\[Obj^{(t)}=\sum_\limits{i=1}^{n}[g_{i} f_{t(x_{i})}+\frac{1}{2} h_{i} f_{t}^{2}(x_{i})]+\Omega (f_{t})\]

&lt;p&gt;其中，$g_{i}=\partial_{\hat{y}^{(t-1)}} l\left(y_{i}, \hat{y}^{(t-1)}\right), \quad h_{i}=\partial_{\hat{y}^{(t-1)}}^{2}l\left(y_{i}, \hat{y}^{(t-1)}\right)$。&lt;/p&gt;

&lt;p&gt;可以看出，目标函数仅依赖每个样本在误差函数上的一阶导数$g$和二阶导数$h$，这里也提示了XGBoost与GBDT在目标函数的一个差别：XGBoost考虑了误差函数的二阶导数。&lt;/p&gt;

&lt;h4 id=&quot;312-正则化项&quot;&gt;3.1.2 正则化项&lt;/h4&gt;

&lt;p&gt;在树模型中，正则化项的加入一般是为了控制树的规模。XGBoost目标函数的正则化项的定义如下：&lt;/p&gt;

\[\Omega(f)=\gamma T+\frac{1}{2} \lambda\Vert w\Vert^2\]

&lt;p&gt;其中，$T$表示叶子结点的个数，$w$表示叶子结点的分数，将二者作为惩罚项时，即要求在训练过程中，生成的树的叶子结点尽可能少，且叶子结点的数值不会过大，从而达到防止过拟合的目的。&lt;/p&gt;

&lt;h4 id=&quot;313-xgboost的目标函数&quot;&gt;3.1.3 XGBoost的目标函数&lt;/h4&gt;

&lt;p&gt;回顾上面得到的目标函数的表达式：&lt;/p&gt;

\[Obj^{(t)}=\sum_\limits{i=1}^{n}[g_{i} f_{t(x_{i})}+\frac{1}{2} h_{i} f_{t}^{2}(x_{i})]+\Omega (f_{t})\]

&lt;p&gt;其中$f_t(x)$可以写为：&lt;/p&gt;

\[f_t(x)=w_{q(x)},\quad w\in\mathrm{R}^T,q:\mathrm{R}^d \rightarrow\{1,2,...,T\}\]

&lt;p&gt;$w$表示树的叶子结点的权重，$q$表示树的结构，给定一个输入，结构函数将其&lt;strong&gt;映射&lt;/strong&gt;到叶子结点的索引，再通过权重向量$w$（可以看到权重向量的维度为叶子结点的个数），得到对应的叶子结点的分数。&lt;/p&gt;

&lt;p&gt;由以上定义，可以将上述目标函数修改为：&lt;/p&gt;

\[\begin{aligned} Obj^{(t)}
&amp;amp; \simeq \sum_\limits{i=1}^n[g_i f_t(x_i)+\frac{1}{2}h_i f_t^2(x_i)] + \Omega(f_t) \\
&amp;amp;=\sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right) w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\lambda\right) w_{j}^{2}\right]+\gamma T
\end{aligned}\]

&lt;p&gt;其中$I_j$定义为每个叶子节点$j$上面样本索引的集合：$I_{j}={i \mid q(x_{i})=j}$，值得注意的是，这一步的目标函数的转换有两种累加形式，第一个是样本角度的累加，通过引入$f_t(x)=w_{q(x)}$后，转化为叶子结点个数的累加。（回忆前述定义的树结构映射$q$，其能够将样本$x_i$映射到树的一个叶子结点上。）&lt;/p&gt;

&lt;p&gt;在上述目标函数上，定义$G_j=\sum_\limits{i \in I_{j}} g_{i}$，$H_j=\sum_\limits{i \in I_{j}} h_{i}$，将目标函数简写为：&lt;/p&gt;

\[Obj^{(t)}=\sum_\limits{j=1}^T[G_jw_j+\frac{1}{2}(H_j+\lambda)w_j^2]+\gamma T\]

&lt;p&gt;这是一个二次函数的最优化问题，要计算$w_j$，可以将目标函数对$w_j$求偏导后另为$0$，可得：&lt;/p&gt;

\[w_j^*=-\frac{G_j}{H_j+\lambda}\]

&lt;p&gt;将最优$w_j$代回目标函数表达式，有：&lt;/p&gt;

\[Obj=-\frac{1}{2} \sum_\limits{j=1}^{T} \frac{G_{j}^{2}}{H_{j}+\lambda}+\gamma T\]

&lt;h3 id=&quot;32-xgboost节点分裂&quot;&gt;3.2 XGBoost节点分裂&lt;/h3&gt;

&lt;p&gt;前面我们定义了XGBoost的目标函数$Obj$，它描述了在给定树结构的情况下，目标函数所能减少的最大幅度。我们可以将其称为“结构分数（structure score）”，基于此，接下来讨论一下XGBoost在建树过程中的一些细节。&lt;/p&gt;

&lt;h4 id=&quot;321-xgboost节点分裂方式&quot;&gt;3.2.1 XGBoost节点分裂方式&lt;/h4&gt;

&lt;p&gt;在树模型中，一棵树是由节点一分为二、生成的子节点继续分裂后逐渐形成的。那么XGBoost中节点的分裂方式有哪些呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1）贪心地枚举所有树的结构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于上文可知，在确定了一个树的结构后，我们便可以计算出该结构下&lt;strong&gt;最好的&lt;/strong&gt;分数。那么一个直观的想法是，枚举不同的树结构，根据打分函数确定一个具有最优结构的树，并将其加入模型当中。但这个过程的可能性几乎是无穷多种，我们可以以贪心的方式来构建，比如，从根节点开始，遍历所有的特征，针对每一个特征，**先对该特征按照取值排序 **，然后进行线性扫描，获得最好的分割点，计算由这个特征加入所带来的增益（Gain），然后选取增益最大的特征作为当前节点的最终分裂特征。增益的计算方式为：&lt;/p&gt;

\[\text { Gain }=\frac{1}{2}\left[\frac{G_{L}^{2}}{H_{L}+\lambda}+\frac{G_{R}^{2}}{H_{R}+\lambda}-\frac{\left(G_{L}+G_{R}\right)^{2}}{H_{L}+H_{R}+\lambda}\right]-\gamma\]

&lt;p&gt;表示分类后左子树的目标函数加上右子树的目标函数减去不分割时的分数，再减去加入新的叶子结点所带来的cost。&lt;/p&gt;

&lt;p&gt;上述描述中有两点需要注意：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;对于一个特征，按照其取值进行排序，线性扫描计算增益&lt;/p&gt;

    &lt;p&gt;这里举一个例子，假设对年龄这个特征，我们可以按照年龄的大小对样本进行排序。假设有五个人$A,B,C,D,E$，则划分方式有以下四种（使用“$\mid$”符号表示划分）：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;$A\mid B,C,D,E$&lt;/li&gt;
      &lt;li&gt;$A,B\mid C,D,E$&lt;/li&gt;
      &lt;li&gt;$A,B,C\mid  D,E$&lt;/li&gt;
      &lt;li&gt;$A,B,C,D\mid E$&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;每一种划分均将样本分成两个子集，针对每个子集，按照增益的计算方式，计算出对应的分数即可。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;引入分割不一定使情况变得更好&lt;/p&gt;

    &lt;p&gt;在一些情况下，可能出现分割后的增益太小的情况，这种分割会增大模型的复杂度，得不偿失，针对这种情况，XGBoost增加了有关叶子结点的惩罚项$\gamma$，即当分割所带来的收益小于$\gamma$时，取消此次分割，这里相当于对树做了预剪枝。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;2）近似算法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当数据太大，无法进行直接计算时，采用近似算法【TODO】&lt;/p&gt;

&lt;h4 id=&quot;322-停止分裂条件&quot;&gt;3.2.2 停止分裂条件&lt;/h4&gt;

&lt;p&gt;停止分裂条件定义了迭代算法的终止条件，一般地，XGBoost设置的停止分裂条件有如下几种：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;当引入的分裂带来的增益小于给定阈值的时候，取消此次分裂，这里相当于预剪枝&lt;/li&gt;
  &lt;li&gt;设置一个树的最大深度参数max_depth，当分裂进行到此深度时则停止分裂，防止过拟合&lt;/li&gt;
  &lt;li&gt;当样本权重小于给定阈值时，停止建树，设置一个参数min_child_weight，当一个叶子结点包含的样本数量过少时，停止分裂&lt;/li&gt;
  &lt;li&gt;树的最大数量&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;统计学习方法&lt;/li&gt;
  &lt;li&gt;https://blog.csdn.net/v_JULY_v/article/details/81410574&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sun, 28 Mar 2021 20:52:03 +0800</pubDate>
        <link>http://localhost:4000//2021/03/XGBoost%E7%90%86%E8%A7%A3</link>
        <guid isPermaLink="true">http://localhost:4000//2021/03/XGBoost%E7%90%86%E8%A7%A3</guid>
        
        <category>Machine Learning</category>
        
        <category>Boosting</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>集成学习小结</title>
        <description>&lt;p&gt;集成学习主要有两个思路，Bagging和Boosting。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Bagging&lt;/p&gt;

    &lt;p&gt;独立训练（可并行）多个基分类器，使用投票法或者平均法集成所有基分类器的结果。&lt;/p&gt;

    &lt;p&gt;bagging的目标是为了减小方差。&lt;/p&gt;

    &lt;p&gt;典型算法：RandomForest&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Boosting&lt;/p&gt;

    &lt;p&gt;为每个样本赋一个相同的权重，在一次迭代中，一个基模型对样本的估计有对有错，对于分错的样本，增加其权重，分对的样本，则减少其权重。在进行N次迭代后，得到N个简单的分类器（basic learner），将这些分类器通过权重进行组合，即是boosting模型（方法 ）。&lt;/p&gt;

    &lt;p&gt;典型算法：Adaboost、GBDT、XGBoost、LightGBM、CatBoost&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下文对上述Boosting和Bagging典型算法的思想、实现方式和优缺点进行总结对比。&lt;/p&gt;

&lt;h2 id=&quot;randomforest&quot;&gt;RandomForest&lt;/h2&gt;

&lt;p&gt;RF是bagging的扩展，以CART为基学习器，学习过程为：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;随机选择样本（有放回抽样）&lt;/p&gt;

    &lt;p&gt;随机选择样本是bagging的特点&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;随机选择特征&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;仅选择$\sqrt{n}$个特征进行决策树的生成（会一定程度上增大偏差），多棵决策树会使得RF的方差降低&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;构建决策树&lt;/p&gt;

    &lt;p&gt;构建决策树时，每棵决策树都最大可能的进行生成而不进行剪枝。&lt;/p&gt;

    &lt;p&gt;多个决策树投票/平均：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;分类：简单投票法&lt;/li&gt;
      &lt;li&gt;回归：简单平均&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;模型方差小，预测准确性高&lt;/li&gt;
  &lt;li&gt;树构建可并行化，无需剪枝，大数据集、特征数量大时依然适用&lt;/li&gt;
  &lt;li&gt;无需特征选择，可以给出特征重要性&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;容易过拟合&lt;/li&gt;
  &lt;li&gt;取值划分较多的属性对RF的影响更大，这种属性权重并不可靠&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;RF的重要特性是&lt;strong&gt;不用对其进行交叉验证&lt;/strong&gt;或者使用一个独立的测试集获得无偏估计，RF在生成的过程中可以对误差进行无偏估计，由于每个基学习器仅使用了训练集中约&lt;strong&gt;63.2%&lt;/strong&gt;的样本，剩下约&lt;strong&gt;36.8%&lt;/strong&gt;的样本可用做验证集来对模型的泛化能力进行袋外估计。&lt;/p&gt;

&lt;h2 id=&quot;adaboost&quot;&gt;Adaboost&lt;/h2&gt;

&lt;p&gt;Adaboost的学习过程：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;初始化样本权重（$N$个样本：每个样本权重$\frac{1}{N}$），抽样得到一批样本，训练第一个基分类器&lt;/li&gt;
  &lt;li&gt;计算上一个基分类器的错误率，记为$\epsilon$，通过其计算出基分类器的权重：$\alpha=\frac{1}{2}\ln\frac{1-\epsilon}{\epsilon}$&lt;/li&gt;
  &lt;li&gt;根据基分类器的分类结果调整样本的权重，正确分类的样本降低权重，错误分类的增加权重。（权重越大，表示分类难度越大）（通过此种方式，使得后续的基分类器更关注分错的样本）&lt;/li&gt;
  &lt;li&gt;循环执行2～3步，直至误差小于某一个阈值或分类器个数达到上限&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对弱分类器进行级联，提高模型精度&lt;/li&gt;
  &lt;li&gt;可以使用多样的基分类器&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;基分类器数量不好确定（需要通过交叉验证确定）&lt;/li&gt;
  &lt;li&gt;对不平衡数据的分类效果不佳&lt;/li&gt;
  &lt;li&gt;训练比较耗时&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;gbdtgradient-boost-decision-tree&quot;&gt;GBDT（Gradient Boost Decision Tree）&lt;/h2&gt;

&lt;p&gt;一般的boosting算法关注每一轮迭代中的正/误样本的权重，而GBDT的每一次迭代都是为了减少上一次迭代的&lt;strong&gt;残差&lt;/strong&gt;（通过在残差减小的梯度方向上建立模型），即利用损失函数的负梯度方向在当前模型的值作为残差的近似值，进而拟合一棵CART&lt;strong&gt;回归树&lt;/strong&gt;，GBDT会累加所有（回归）树的结果。&lt;/p&gt;

&lt;p&gt;GBDT的执行流程：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;使用训练样本训练第一个弱分类器，并将模型结果与真实结果进行比较，得到模型的残差&lt;/li&gt;
  &lt;li&gt;使用上一步骤中得到的残差训练下一个分类器，再次比较结果，计算残差&lt;/li&gt;
  &lt;li&gt;循环执行1～2步，直至残差小于某一个阈值或分类器个数达到上限&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以处理各种类型的数据&lt;/li&gt;
  &lt;li&gt;调参时间较少的情况下能够获得较高的准确度、泛化能力强&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;高维稀疏数据集上的表现不如支持向量机和神经网络、文本特征的处理能力弱于数值特征&lt;/li&gt;
  &lt;li&gt;基于boosting思想，需要串行训练，只能在决策树内部进行一些局部的并行化手段&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;xgboost&quot;&gt;XGBoost&lt;/h2&gt;

&lt;p&gt;XGBoost基于GBDT，可以处理分类任务，也可以处理回归任务。与GBDT的最大区别是，XGBoost对目标函数进行二阶泰勒展开，从而求出下一步需要拟合的树的叶子结点的权重。&lt;/p&gt;

&lt;p&gt;XGBoost与GBDT的区别：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;GBDT是机器学习算法，而XGBoost是GBDT的一种实现&lt;/li&gt;
  &lt;li&gt;在使用CART作为基分类器时，XGB加入了正则项（树的叶子结点个数、每个叶子结点上输出的分数的L2范数的平方和）来控制模型的复杂度，防止过拟合&lt;/li&gt;
  &lt;li&gt;GBDT训练时仅使用了代价函数的一阶导数，XGB使用了一阶和二阶导数（xgboost支持自定义代价函数（二阶可导即可））&lt;/li&gt;
  &lt;li&gt;在XGB中有一个Shrinkage操作，对应到XGB实现中的eta参数，在进行一轮迭代后，将叶子结点上的权重乘以该系数，来削弱当前基分类器的影响，增大后续的学习空间（实际操作中，eta设置的小一点，迭代次数可以稍微设置大一些）&lt;/li&gt;
  &lt;li&gt;XGB使用列抽样技术（column sampling），能够在减少计算的同时，减弱过拟合倾向&lt;/li&gt;
  &lt;li&gt;GBDT对缺失值没有处理，XGB能够自动学习缺失值的处理方法&lt;/li&gt;
  &lt;li&gt;XGB支持决策树构建级别的并行化，在决策树学习过程中，确定最优分割点时，需要对特征的取值进行排序，XGB在训练之前对数据作了预排序并保存为block结构，在后续的训练过程中复用此结构，另外，在进行结点分裂时，计算各个特征的增益也可以使用多线程并行进行&lt;/li&gt;
  &lt;li&gt;GBDT使用CART作为基分类器，XGB支持多种类型的基分类器&lt;/li&gt;
  &lt;li&gt;GBDT每次迭代使用全部数据，XGB使用自助法抽样数据&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算效率高，使用二阶导数&lt;/li&gt;
  &lt;li&gt;缺点：每次迭代需要遍历整个数据集，内存占用大&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;lightgbm&quot;&gt;LightGBM&lt;/h2&gt;

&lt;p&gt;LGB是一个实现了GBDT算法的高效的分布式框架。&lt;/p&gt;

&lt;p&gt;降低训练复杂度可以从两个角度入手（在尽可能保证精度的前提下）：减少特征、减少数据量，在LightGBM中，对应的手段是GOSS和EFB。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;GOSS（Gradient-based One-side Sampling）&lt;/p&gt;

    &lt;p&gt;训练过程中，每个数据实例拥有不同的梯度，梯度大的实例对信息增益的影响更大，因此，在下采样时应尽可能保留梯度大的样本（通过阈值或百分比来限制），随机去掉梯度小的样本。这个技术能够获得比随机采样更精确的的结果。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;EFB（Exclusive Feature Bundling）&lt;/p&gt;

    &lt;p&gt;在实际应用中，特征之间可能存在着互斥的情况，EFB对互斥特征进行绑定，将绑定问题约束到图着色问题，通过贪心算法求近似解，通过此种方式减少了特征的数量。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;LightGBM与XGBoost的区别：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;内存方面：在计算分类特征的增益时，XGB使用预排序法（pre-sorted）处理节点分类（比较精确，但时间开销比较大）；LGB使用基于histogram的决策树算法，节省了内存占用（～$\frac{1}{8} \cdot$pre-sorted算法）&lt;/li&gt;
  &lt;li&gt;效率方面：决策树算法的主要操作有两个：分割点寻找和数据分割，在第一个操作上，pre-sorted和histogram算法的时间复杂度是一样的，在数据分割操作上，histogram比pre-sorted要快（histogram中，所有特征共享一个索引，而pre-sorted中，每个特征对应一个索引），此外，histogram还减少了计算分割点增益的次数&lt;/li&gt;
  &lt;li&gt;通信方面：histogram的通信代价远小于pre-sorted，适用于分布式计算&lt;/li&gt;
  &lt;li&gt;XGB的生成策略是level-wise（不容易过拟合，但效率低，在分裂时，部分增益小的树也进行了增长），LGB使用leaf-wise（高效，但容易生成深度过大的树，从而导致过拟合，因此需要限制最大深度）&lt;/li&gt;
  &lt;li&gt;训练精度方面：histogram由于无法找到精确的分割点，与pre-sorted相比，相当于通过牺牲精度来换取效率&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;catboostcategory-boosting&quot;&gt;CatBoost（Category Boosting）&lt;/h2&gt;

&lt;p&gt;CatBoost是以对称决策树为基学习器的GBDT框架，能够高效地处理类别型特征，此外，CatBoost还解决了梯度偏差（Graident Bias）和预测偏移（Prediction Shift）的问题，能够减弱过拟合现象，提高预测准确性。&lt;/p&gt;

&lt;p&gt;CatBoost的学习算法基于GPU实现，打分算法基于CPU实现。&lt;/p&gt;

&lt;p&gt;CatBoost相对于XGB和LGB的改进：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;能够自动采用特殊方式处理类别型特征&lt;/li&gt;
  &lt;li&gt;对类别特征进行组合，丰富了特征种类&lt;/li&gt;
  &lt;li&gt;基模型采用对称树&lt;/li&gt;
  &lt;li&gt;使用排序提升的方法对抗训练集中的噪声点，从而避免梯度估计的偏差，解决了预测偏移的问题&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;catboost如何处理类别特征categorical-features&quot;&gt;CatBoost如何处理类别特征（categorical features）&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;对数据做一些统计，计算某个category出现的频率，再加上一些超参数，生成新的数值型特征&lt;/li&gt;
  &lt;li&gt;对数据进行若干种排列，在每一轮建树之前，随机选择一种数据排列来生成树&lt;/li&gt;
  &lt;li&gt;对category特征进行组合，在组合数量过大时，CatBoost通过贪心算法选择来选择最好的一部分组合&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;性能强，可以匹敌任何先进的机器学习算法&lt;/li&gt;
  &lt;li&gt;鲁棒性高，减少了超参数调整的需求，降低了过拟合的风险，模型的泛用性更强&lt;/li&gt;
  &lt;li&gt;实用性强：体现在可以自动处理数值特征和类别特征&lt;/li&gt;
  &lt;li&gt;可扩展：支持自定义loss函数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;对类别特征的处理对时间和空间的需求比较大&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;模型随机种子的设定会影响模型的预测结果&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;refs&quot;&gt;Refs.&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://marian5211.github.io/2018/03/12/&quot;&gt;gbdt-xgboost-lightGBM比较&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/129810143&quot;&gt;集成算法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1603.02754.pdf&quot;&gt;XGBoost: A Scalable Tree Boosting System&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.msra.cn/zh-cn/news/features/lightgbm-20170105&quot;&gt;MSRA: LighGBM介绍&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/102540344&quot;&gt;深入理解CatBoost&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.audentia-gestion.fr/MICROSOFT/lightgbm.pdf&quot;&gt;LightGBM: A Highly Efficient Gradient Boosting Decision Tree&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.09516.pdf&quot;&gt;CatBoost: unbiased boosting with categorical features&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/abhinand05/catboost-a-deeper-dive&quot;&gt;Catboost: A Deeper Dive&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/102570430&quot;&gt;Catboost完全指南&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sat, 27 Feb 2021 17:21:09 +0800</pubDate>
        <link>http://localhost:4000//2021/02/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93</link>
        <guid isPermaLink="true">http://localhost:4000//2021/02/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93</guid>
        
        <category>集成学习</category>
        
        <category>Machine Learning</category>
        
        
        <category>算法</category>
        
      </item>
    
      <item>
        <title>优化算法</title>
        <description>&lt;p&gt;根据优化目标是否受条件约束，优化算法分为无约束优化算法和带约束优化算法。&lt;/p&gt;

&lt;p&gt;常见的无约束优化算法有：梯度下降法（最速下降法）、牛顿法、拟牛顿法、共轭梯度法、启发式算法（遗传算法、模拟退火、蚁群算法等）。&lt;/p&gt;

&lt;p&gt;常见的带约束优化问题可以按照约束条件分为两类：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;等式约束优化问题&lt;/li&gt;
  &lt;li&gt;不等式约束优化问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于第一类，可以使用拉格朗日乘数法，转变为无约束优化问题；
对于第二类，可引入KKT条件，将不等式约束优化问题转化为等式约束优化问题，然后使用等式约束优化问题的求解方法来处理。&lt;/p&gt;

&lt;p&gt;以下简单介绍无约束优化算法：梯度下降法、牛顿法、拟牛顿法和共轭梯度法。&lt;/p&gt;

&lt;h3 id=&quot;梯度下降法gradient-decent-gd&quot;&gt;梯度下降法（Gradient Decent, GD）&lt;/h3&gt;

&lt;p&gt;梯度下降法在深度学习中应用非常广泛，梯度下降算法的优化思想是，使用当前目标函数的负梯度方向作为搜索方向，由于这个方向是目标函数下降最快的方向，因此梯度下降法又称为最速下降法。在梯度下降法执行过程中，越接近目标点，梯度越小，每次更新的步长就会越小。
对于目标函数为凸的情况，GD算法总能找到最优解，但在非凸情况下，则不能保证。
梯度下降法实现简单，在大量样本上执行速度快。其缺点在于，需要手工调整超参数，如学习率、终止条件等；另外，梯度下降本质上是一个序列算法，无法很好地支持并行计算。&lt;/p&gt;

&lt;p&gt;在实际应用中，常使用批梯度下降法（Batch Gradient Decent，BGD）和小批量梯度下降法（mini-Batch Gradient Decent），及随机梯度下降法（Stochastic Gradient Decent，SGD），BGD、mini-BGD、SGD的区别在于，BGD一次迭代使用所有的训练数据计算梯度方向，对于数据量较大的情况，执行速度较慢，mini-BGD和SGD则分别使用一小批样本和单个样本对参数进行更新，SGD每次迭代的目标是最小化单个样本的损失，通过增加迭代次数，来换取执行效率的提升，同时，在大量数据的前提下，其优化方向也趋于最优解。mini-BGD则是BGD和SGD的折衷选择。&lt;/p&gt;

&lt;h3 id=&quot;牛顿法newtons-method&quot;&gt;牛顿法（Newton’s Method）&lt;/h3&gt;

&lt;p&gt;牛顿法在机器学习领域的应用也比较多，其基本思想是，利用参数当前位置的一阶导数（梯度）和二阶导数（Hessian矩阵）对目标函数进行二次近似，然后将二次模型的极小点作为新的迭代点，重复上述过程，直至极小值满足精度要求。牛顿法运行速度很快，而且可以高度逼近最优解。&lt;/p&gt;

&lt;p&gt;记优化目标函数为$f(x)$，牛顿法在一维情形中的表述如下：&lt;/p&gt;

&lt;p&gt;对$f(x)$进行二阶展开，忽略高阶余项（为了方便表述，以下泰勒展开公式中，使用等号，下同），有：&lt;/p&gt;

\[f(x) = f(x_{k})+\nabla f(x_{k})^T(x-x_{k})+\frac{1}{2} (x-x_{k})^T \nabla^2 f(x_{k})(x-x_{k})\]

&lt;p&gt;上式求$x$求导，并令其为0，可得：&lt;/p&gt;

\[\nabla f(x)=\nabla f(x_{k})+\nabla^{2} f(x_{k})(x-x_{k})=0\]

&lt;p&gt;即：&lt;/p&gt;

\[x = x_k - \frac{\nabla f(x_{k})}{\nabla^{2} f(x_{k})}\]

&lt;p&gt;其中，$\nabla^{2} f(x_{k})$为Hassian阵，可简记为H，&lt;/p&gt;

\[H(x)=\left[\frac{\partial^{2} f}{\partial x_{i} \partial x_{j}}\right]_{n \times n}\]

&lt;p&gt;牛顿法的执行流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;设定终止误差$0 \leq \epsilon \ll 1$，设置初始点$x_0 \in \mathrm{R}^n$，$k=0$&lt;/li&gt;
  &lt;li&gt;计算$g_k=\nabla f(x_{k})$，若$\mid\mid g_k \mid\mid \leq \epsilon$，算法终止，输出$x^* =x_k$&lt;/li&gt;
  &lt;li&gt;计算$H_k=\nabla^{2} f(x_{k})$，计算搜索方向$d_k=-H_k^{-1}g_k$，这个搜索方向又称为“牛顿方向“&lt;/li&gt;
  &lt;li&gt;令$x_{k+1}=x_k+\lambda d_k$，$k=k+1$，转至2&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在第四步中，需要设置一个接近0的参数$\lambda$，需要这个参数来保证$x_{k+1}$在$x_k$的邻域内，以确保我们可以在泰勒展开时能够忽略高阶项。$\lambda$的选取可以使用直线搜索法（line search），即在一定的区间范围内设定$\lambda$的值，选择函数值下降最快的值作为最优$\lambda$。&lt;/p&gt;

&lt;p&gt;从几何的角度，牛顿法使用一个二次曲面来拟合当前所处位置的局部曲面，而梯度下降则是用一个平面来拟合，通常情况下，牛顿法的下降路径更符合实际的最优下降路径，且收敛速度更快（其具有二阶收敛特性），不足之处在于，牛顿法每一次迭代均需要计算一次目标函数的二阶导数（对应高维情况的Hessian矩阵），计算过程比较复杂。&lt;/p&gt;

&lt;p&gt;当然，牛顿法也面临一些问题，主要是：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;牛顿法与梯度下降类似，也在寻找梯度为0的点，所以也会面临鞍点和局部极小值的问题&lt;/li&gt;
  &lt;li&gt;Hessian求逆的代价很高&lt;/li&gt;
  &lt;li&gt;在某些情况下Hessian阵可能不可逆&lt;/li&gt;
  &lt;li&gt;每次迭代过程中，牛顿法不能保证收敛到最优解，可以使用直线搜索法或可信域搜索来动态调整牛顿方向的步长，这里可以衍生出可信域牛顿法（Trust Region Newton Methods）。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;拟牛顿法quasi-newton-methods&quot;&gt;拟牛顿法（Quasi-Newton Methods）&lt;/h3&gt;

&lt;p&gt;在牛顿法中提到，迭代过程中在求解线性方程组时，需要计算Hessian矩阵的逆矩阵，Hessian逆矩阵求解比较耗时，且有些情况下Hessian矩阵是不可逆的，为此，提出了一些改进算法，典型的是拟牛顿法，其主要思想是，不直接求解$H$矩阵及其逆矩阵，而是通过其他手段获得它们。具体地，构造一个正定矩阵来替代$H$矩阵（或其逆矩阵），将这个替代矩阵用于牛顿法的求解中。&lt;/p&gt;

&lt;p&gt;仿照牛顿法中的处理方式，将$f(x)$在$x_{k+1}$处展开并忽略高阶项，有：&lt;/p&gt;

\[f(x)= f(x_{k+1})+\nabla f(x_{k+1})^T(x-x_{k+1})+\frac{1}{2} (x-x_{k+1})^T \nabla^2 f(x_{k})(x-x_{k+1})\]

&lt;p&gt;对等号两侧求梯度，有：&lt;/p&gt;

\[\nabla f(x) = \nabla f(x_{k+1})+\nabla^{2} f(x_{k+1})(x-x_{k+1})\]

&lt;p&gt;令$x=x_k$，有：&lt;/p&gt;

\[\nabla f(x_{k+1})-\nabla f(x_k) = \nabla^{2} f(x_{k+1})(x_{k+1} - x_k)\]

&lt;p&gt;沿用上述牛顿法中的记号，上式简写为：&lt;/p&gt;

\[g_{k+1}-g_{k}=H_{k+1}(x_{k+1}-x_{k})\]

&lt;p&gt;令$x_{k+1}-x_{k}=s_k$，$g_{k+1}-g_{k}=y_k$，则有：&lt;/p&gt;

&lt;p&gt;$y_k=H_{k+1}s_k$，即$s_k=H_{k+1}^{-1}y_k$&lt;/p&gt;

&lt;p&gt;上述条件称为拟牛顿条件，在拟牛顿方法中构造出的Hessian矩阵需要满足上述条件。&lt;/p&gt;

&lt;p&gt;典型的拟牛顿方法有DFP算法（Davidon-Fletcher-Powell）、BFGS算法（Broyden-Fletcher-Goldfarb-Shanno Algorithm）、Broyden类算法（Broyden’s algorithm）、L-BFGS算法（Limited-memory BFGS）、SR1算法（Symmetric rank-one）等，下文主要介绍DFP算法、BFGS算法、Broyden类算法。&lt;/p&gt;

&lt;h4 id=&quot;dfp算法&quot;&gt;DFP算法&lt;/h4&gt;

&lt;p&gt;DFP算法使用$G_k$作为$H_k^{-1}$的近似，并假设$G_k$的迭代过程包含两个附加项：&lt;/p&gt;

\[G_{k+1}=G_{k}+P_{k}+Q_{k}\]

&lt;p&gt;其中$P_k$和$Q_k$为待定矩阵，有：&lt;/p&gt;

\[G_{k+1} y_{k}=G_{k} y_{k}+P_{k} y_{k}+Q_{k} y_{k}\]

&lt;p&gt;为了使$G_{k+1}$满足拟牛顿条件，可以让$P_k$和$Q_k$满足：&lt;/p&gt;

\[P_{k} y_{k}=\delta_{k},Q_{k}=-\frac{G_{k} y_{k} y_{k}^{T} G_{k}}{y_{k}^{T} G_{k} y_{k}}\]

&lt;p&gt;带入$G_{k+1}$的迭代公式可得：&lt;/p&gt;

\[G_{k+1}=G_{k}+\frac{\delta_{k} \delta_{k}^{T}}{\delta_{k}^{T} y_{k}}-\frac{G_{k} y_{k} y_{k}^{T} G_{k}}{y_{k}^{T} G_{k} y_{k}}\]

&lt;p&gt;如果$G_0$是正定的，则可以证明，迭代过程中的$G_k$都是正定的。&lt;/p&gt;

&lt;p&gt;DFP算法流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;给定初值$x_0$，终止误差$\epsilon$；取$G_0$为正定矩阵，令$k=0$&lt;/li&gt;
  &lt;li&gt;计算$g_k=g(x_0)$，如果$\Vert g_k \Vert \lt \epsilon$则终止迭代，近似解$x^* =x_k$；否则执行下一步&lt;/li&gt;
  &lt;li&gt;计算$p_k=-G_kg_k$&lt;/li&gt;
  &lt;li&gt;执行一维搜索，求$\lambda$使得：
\(f(x^{(k)}+\lambda_{k} p_{k})=\min_\limits{\lambda \geq 0} f(x^{(k)}+\lambda p_{k})\)&lt;/li&gt;
  &lt;li&gt;$x_{k+1}=x_k+\lambda p_k$&lt;/li&gt;
  &lt;li&gt;计算$g_{k+1}=g(x_{k+1})$，如果$\Vert g_k \Vert \lt \epsilon$则终止迭代，近似解$x^*=x_k$；否则，计算$G_{k+1}=G_{k}+\frac{\delta_{k} \delta_{k}^{T}}{\delta_{k}^{T} y_{k}}-\frac{G_{k} y_{k} y_{k}^{T} G_{k}}{y_{k}^{T} G_{k} y_{k}}$&lt;/li&gt;
  &lt;li&gt;$k=k+1$，执行第3步&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;bfgs算法&quot;&gt;BFGS算法&lt;/h4&gt;

&lt;p&gt;BFGS算法的思想是构造Hessian矩阵$H_k$的近似矩阵$B_k$，并通过迭代来更新这个矩阵：&lt;/p&gt;

\[B_{k+1}=B_k+\Delta B_k\]

&lt;p&gt;近似矩阵的初值$B_0$为单位阵$I$，每次迭代需要修正$\Delta B_k $，迭代公式为：&lt;/p&gt;

\[\Delta B_k=\alpha uu^T+ \beta vv^T\]

&lt;p&gt;其中，$u=y_k$，$v=B_ks_k$，$\alpha=\frac{1}{y_k^T s_k}$，$\beta=-\frac{1}{s_k^TB_k s_k}$&lt;/p&gt;

&lt;p&gt;代入$\Delta B_k$得：&lt;/p&gt;

\[\Delta B_{k}=\frac{y_{k}{y_{k}^T}}{y_{k}^{T} s_{k}}-\frac{B_{k} s_{k}s_{k}^{T} B_{k}}{s_{k}^{T} B_{k} s_{k}}\]

&lt;p&gt;算法流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;给定初值$x_0$，终止误差$\epsilon$，令$B_0=I$，$k=0$&lt;/li&gt;
  &lt;li&gt;计算搜索方向$d_k=-B_k^{-1}g_k$&lt;/li&gt;
  &lt;li&gt;计算搜索步长$\lambda_k$，令$s_k=\lambda_kd_k$，$x_{k+1}=x_k+s_k$&lt;/li&gt;
  &lt;li&gt;如果$\Vert g_{k+1}\Vert \lt \epsilon$，则终止迭代&lt;/li&gt;
  &lt;li&gt;计算$y_k=g_{k+1}-g_k$&lt;/li&gt;
  &lt;li&gt;计算$B_{k+1} = B_k + \frac{y_{k}{y_{k}^T}}{y_{k}^{T} s_{k}}-\frac{B_{k} s_{k}s_{k}^{T} B_{k}}{s_{k}^{T} B_{k} s_{k}}$&lt;/li&gt;
  &lt;li&gt;令$k=k+1$，跳转步骤2&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;broyden类算法&quot;&gt;Broyden类算法&lt;/h4&gt;

&lt;p&gt;前置：Sherman-Morrison公式：&lt;/p&gt;

&lt;p&gt;假设$A$为$n$阶可逆矩阵，$u,v$是$n$维向量，$t$为常量，且$A+uv^T$可逆，则：&lt;/p&gt;

\[\left(A+\frac{u v^{T}}{t}\right)^{-1} = A^{-1}- \frac{A^{-1} u v^{T} A^{-1}}{t+v^{T} A^{-1} u}\]

&lt;p&gt;已知BFGS算法的迭代公式如下：&lt;/p&gt;

\[B_{k+1}=B_k + \frac{y_{k}{y_{k}^T}}{y_{k}^{T} s_{k}}-\frac{B_{k} s_{k}s_{k}^{T} B_{k}}{s_{k}^{T} B_{k} s_{k}}\]

&lt;p&gt;对上式应用两次Sherman-Morrison公式$^8$，有：&lt;/p&gt;

\[B_{k+1}^{-1}=\left(I-\frac{\delta_{k} y_{k}^{T}}{\delta_{k}^{T} y_{k}}\right) B_{k}^{-1}\left(I-\frac{\delta_{k} y_{k}^{T}}{\delta_{k}^{T} y_{k}}\right)^{T}+\frac{\delta_{k} \delta_{k}^{T}}{\delta_{k}^{T} y_{k}}\]

&lt;p&gt;记$G_k=B_k^{-1},G_{k+1}=B_{k+1}^{-1}$&lt;/p&gt;

&lt;p&gt;有：&lt;/p&gt;

\[G_{k+1}=\left(I-\frac{\delta_{k} y_{k}^{T}}{\delta_{k}^{T} y_{k}}\right) G_{k}\left(I-\frac{\delta_{k} y_{k}^{T}}{\delta_{k}^{T} y_{k}}\right)^{T}+\frac{\delta_{k} \delta_{k}^{T}}{\delta_{k}^{T} y_{k}}\]

&lt;p&gt;称上式为BFGS算法关于$G_k$的迭代公式，由该公式得到的$G_{k+1}$记为$G^{BFGS}$；&lt;/p&gt;

&lt;p&gt;同理，也可以得到DFP算法关于$G_k$的迭代公式，由该公式得到的$G_{k+1}$记为$G^{DFP}$；&lt;/p&gt;

&lt;p&gt;Broyden类算法将二者进行线性组合：&lt;/p&gt;

\[G_{k+1}=\alpha G^{D F P}+(1-\alpha) G^{B F G S}\]

&lt;p&gt;其中$0\le \alpha \le 1$，由于$G^{BFGS}$和$G^{DFP}$均满足拟牛顿条件，二者的线性组合也满足拟牛顿条件，且$G_{k+1}$为正定矩阵，应用这类迭代公式的算法称为Broyden类算法。&lt;/p&gt;

&lt;h3 id=&quot;共轭梯度法&quot;&gt;共轭梯度法&lt;/h3&gt;

&lt;p&gt;共轭梯度法是共轭方向法的一种，可以用于求解无约束凸二次规划问题：$\min_\limits{x} f(x)= \frac{1}{2}x^TQx+q^Tx$，其中$Q\in\mathbb{R}^{n\times n}$为对称正定矩阵，$q\in \mathbb{R}^n$，$x\in \mathbb{R}^n$。&lt;/p&gt;

&lt;h4 id=&quot;q-conjugate&quot;&gt;Q-conjugate&lt;/h4&gt;

&lt;p&gt;给定正定矩阵$Q$，定义非零向量$x,y$关于Q矩阵Q-conjugate，当且仅当$x^TQy=0$成立，且$x,y$是线性无关的，&lt;/p&gt;

&lt;p&gt;如果能够寻找到$n$个Q-conjugate向量$d_i,d_2,…,d_n$，则这组向量组成$\mathbb{R^n}$中的一组基，空间内任意向量均可由这组向量表示。共轭梯度法通过寻找这样一组Q-conjugate的基，将目标函数分为许多方向，并在这些方向上分别求出极值，所有方向上的极值的和作为整体目标函数的极值。&lt;/p&gt;

&lt;p&gt;给定目标函数$f(x)$，寻找一组方向向量$d_1,d_2,…,d_n \in \mathbb{R}^n$，依次按照这组方向向量中的方向对点$x_i\in \mathbb{R}^n$进行更新，对每一个方向$d_i \in \mathbb{R}^n$，寻找合适的步长$\lambda_i$，使得$f(x)$在该方向上取得最小值，在上述过程中，要求在在方向向量$d_i$上进行更新时，不会影响方向$d_j$上的更新结果，其中$j\lt i$，也即，$x_{k+1}$使$f(x)$在方向$d_k$上取得最小值，且能够使得$f(x)$在$d_j,0\le j\lt k$上保持最小值。由于这组方向两两共轭，因此这种方法称为共轭梯度法。&lt;/p&gt;

&lt;p&gt;如果存在满足上述要求的一组方向，则可以保证经过$n$次迭代后，找到$f(x)$的全局极小值。&lt;/p&gt;

&lt;p&gt;执行流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;任意设置初始点$x_0$，初始方向向量$d_0=\nabla f(x_0)$&lt;/li&gt;
  &lt;li&gt;判断$\nabla f(x_i)=0$，如果是，返回$x_i$，否则，执行3&lt;/li&gt;
  &lt;li&gt;进行点的更新$x_{i+1}=x_i + \lambda_i d_i$，其中，$\lambda_{i}=\frac{-d_{i}^{T} \nabla f\left(x_{i}\right)}{d_{i}^{T} Q d_{i}}$，$d_{i}=-\nabla f\left(x_{i}\right)+\gamma_{i-1} d_{i-1}$，$\gamma_{i-1}=\frac{d_{i-1}^{T} Q \nabla f\left(x_{i}\right)}{d_{i-1}^{T} Q d_{i-1}}$&lt;/li&gt;
  &lt;li&gt;循环执行2～3直至找到最优解&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;参考&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/38586401/answer/669303256&quot;&gt;如何理解拉格朗日乘子法？ - 木小易的回答 - 知乎&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://icml.cc/2011/papers/210_icmlpaper.pdf&quot;&gt;On Optimization Methods for Deep Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/sunflower_sara/article/details/81321886?utm_medium=distribute.pc_relevant.none-task-blog-title-10&amp;amp;spm=1001.2101.3001.4242&quot;&gt;深度学习中的优化器&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Broyden–Fletcher–Goldfarb–Shanno_algorithm&quot;&gt;Broyden–Fletcher–Goldfarb–Shanno algorithm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/144736223&quot;&gt;拟牛顿法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/158206612&quot;&gt;限制空间的优化算法：LBFGS，LSR1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.04747.pdf&quot;&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37524275&quot;&gt;Broyden类算法：BFGS算法的迭代公式推导&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37524275&quot;&gt;梯度下降法、牛顿法和拟牛顿法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/28623599&quot;&gt;共轭梯度法&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 25 Nov 2020 06:04:26 +0800</pubDate>
        <link>http://localhost:4000//2020/11/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95</link>
        <guid isPermaLink="true">http://localhost:4000//2020/11/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95</guid>
        
        <category>Optimization</category>
        
        <category>Machine Learning</category>
        
        
        <category>ML</category>
        
      </item>
    
      <item>
        <title>学习率和batch size讨论</title>
        <description>&lt;h2 id=&quot;1-学习率&quot;&gt;1. 学习率&lt;/h2&gt;

&lt;p&gt;在模型训练过程中，学习率是一个非常敏感且重要的参数，在神经网络的反向传播算法中，梯度下降是一种常用的参数求解方法，学习率影响着梯度下降过程中参数更新的步长。通常，神经网络的参数空间很大，梯度下降的求解目标是最小化定义在参数空间中的损失函数$L$，由于参数维度很大，目标函数一般包含着许多局部最小值点（现有的研究证明，局部极小值已经不是影响神经网络效果的最大障碍了，也即，即使我们找不到全局最小值，一个好的优化算法一般总能找到一个“足够好”的局部极小值）。学习率的影响体现在，如果学习率过小，则参数大小更新的速度会很慢，如果在训练开始前，参数没有被很好地初始化，小的学习率很有可能使目标函数陷入一个并不足够好的局部极小值点而无法跳出；相反，如果学习率设置很大，一方面参数更新的幅度很大，对应的目标函数很有可能在参数空间中反复跳动，即使在迭代过程中，模型寻找到了一个足够好的参数组合，较大的更新幅度也会导致有可能在下次迭代中跳出，导致训练过程的不稳定，训练中表现为训练集损失函数波动明显，收敛困难。&lt;/p&gt;

&lt;p&gt;针对学习率的优化有以下几个方面：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;基础学习率的设定&lt;/p&gt;

    &lt;p&gt;一般使用一个区间内的学习率，在一个epoch中，学习率由最小逐渐增加到最大，观察损失函数的变化情况，一般情况下，我们要寻找的合理的学习率区间内的损失函数应具有较高的下降速率。
&lt;img src=&quot;http://shihanmax.top/20201028203345_YZu2rk_lr_finder.jpeg&quot; alt=&quot;lr&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;训练过程中的学习率调整&lt;/p&gt;

    &lt;p&gt;一般的调整方式有：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;初期学习率warmup：训练初期，学习率有一个比较小的值逐渐增加到基础学习率；&lt;/li&gt;
      &lt;li&gt;学习率衰减：训练过程中，学习率以某种衰减曲线形式逐渐减少；&lt;/li&gt;
      &lt;li&gt;循环学习率（Cyclical learning rates）：随着训练过程进行，学习率以循环的方式，逐渐增加至基础学习率，然后逐渐衰减到一个较小值，这个过程循环执行，直至训练结束，过程中，基础学习率本身可能也会以某种方式逐渐衰减。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://shihanmax.top/20201028204513_BsaS8K_Screen-Shot-2018-02-25-at-8.44.49-PM.jpeg&quot; alt=&quot;cyclical lr&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与训练过程中，学习率一直下降相比，学习率在训练过程中增加的一个理论假设是，“短期内，增加学习率会导致损失增加，但长期来看，模型会收敛到一个更优的解”。支撑这一假设的两个偏直觉性的推断是：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;从训练目标来看，我们希望训练的到的参数足够鲁棒，也即输入或参数微小的波动不应该导致目标函数/损失函数发生大幅度的变化，这种变化尤其可能发生在比较狭小的极小值处（sharp minima lead to poor generalization，后文讨论batch size的影响时会提到），训练过程中增加学习率，能够有更大的可能使参数从这种不理想的极小值出跳出；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;同样的，目标函数表面可能存在非常多的鞍点（在某些参数维度上，目标函数取极小值，同时，在其他参数维度上则取最大值），训练过程中增加学习率有助于更快地脱离鞍点，起到加快收敛的作用。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;训练神经网络基本等价于对一个高维非凸函数求最值的问题，这个问题理论上非常困难，但实践中有时又比较简单：在一些简单的任务上，基于梯度下降算法的优化方法总能寻找到全局最优解。但这并不总能实现，神经网络的可训练性受到网络结构设计、优化器的选择、参数的初始化效果、训练数据分布和其它一些因素的共同影响，针对这些因素，实践中没有一套通用的准则来指导。某些特定的网络结构能够使得训练过程更为容易（如skip connections等），这篇文章&lt;a href=&quot;https://arxiv.org/pdf/1712.09913.pdf&quot;&gt;Visualizing the Loss Landscape of Neural Nets &lt;/a&gt;通过可视化的手段分析了神经网络损失函数的结构，概括性分析了这些结构对于训练的影响，以及参数对训练过程的影响。作者发现，随着网络深度的增加，损失函数的非凸性加剧。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://shihanmax.top/20201029204158_fSpDaA_%E6%88%AA%E5%B1%8F2020-10-29%2020.41.50.jpeg&quot; alt=&quot;depth&quot; /&gt;&lt;/p&gt;

&lt;p&gt;并通过实验发现，如果在网络中加入一些短路连接，则损失函数表面则倾向于变得光滑。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://shihanmax.top/20201029204023_N5naCq_%E6%88%AA%E5%B1%8F2020-10-29%2020.40.15.jpeg&quot; alt=&quot;skip-connections&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这篇文章&lt;a href=&quot;https://icml.cc/Conferences/2018/Schedule?showEvent=2780&quot;&gt;Essentially No Barriers in Neural Network Energy Landscape&lt;/a&gt; 证明了，在较大的神经网络中，全局最优解往往不是一个点，而是一个连通的流形（manifold），一个更一般化的说法：如果目标函数存在两个局部最优解，则一定可以通过一条平坦的路径（flat path），使得这两点连通。&lt;/p&gt;

&lt;h2 id=&quot;2-batch-size&quot;&gt;2. batch size&lt;/h2&gt;

&lt;p&gt;在神经网络训练过程中，另一个比较重要的超参数是batch size，为了使每次迭代的计算量是可承受的，我们将所有的训练数据划分为许多个mini-batch，同时为了更充分地利用并行化的优势，应在设备允许的范围内尽量大地设置batch size，人们在实践中发现，增大batch size后，模型在测试集上的表现往往会变差，在&lt;a href=&quot;https://arxiv.org/pdf/1609.04836.pdf&quot;&gt;ON LARGE-BATCH TRAINING FOR DEEP LEARNING: GENERALIZATION GAP AND SHARP MINIMA &lt;/a&gt;的实验中，由batch size变化带来的性能差距甚至能够达到5%。针对此现象，可能的解释如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;batch size增大时，模型倾向于过拟合&lt;/li&gt;
  &lt;li&gt;batch size增大时，优化过程中更有可能遇到鞍点&lt;/li&gt;
  &lt;li&gt;与小batch size训练出的模型相比，大batch size模型在优化过程中缺乏探索性，以致倾向收敛于距初始参数较近的局部最优解&lt;/li&gt;
  &lt;li&gt;batch size变化时，模型收敛到的最优解具有不同的泛化特性&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作者通过统计性实验证明了后两个推论的合理性：增大batch size时，模型倾向于收敛到尖锐的局部最小值处，该处表现为矩阵$\nabla ^2 f$的正特征值更大；相反地，对于较为平坦的局部最小值处对应的$\nabla ^2 f$的特征值则会小得多。 作者强调，由于batch size变化造成的泛化能力差别（generalization gap）并不是由过拟合引起的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://shihanmax.top/20201103203609_IyHglP_%E6%88%AA%E5%B1%8F2020-11-03%2020.36.02.jpeg&quot; alt=&quot;flat&amp;amp;sharp local minima &quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在大型网络中，计算$\nabla ^2 f$的特征值来表征极值点处的尖锐程度的代价十分高昂，因此作者提出了一种替代方案用于表征目标函数任一点处的尖锐程度，并通过实验对比了batch size变化时，目标函数尖锐程度的变化情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://shihanmax.top/20201103204854_WbTFyO_%E6%88%AA%E5%B1%8F2020-11-03%2020.48.44.jpeg&quot; alt=&quot;sharpness-bs &quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了尝试解决大batch size遇到的问题，作者尝试了数据扩增、使用更加鲁棒的优化器等措施，但实验证明，在较大的batch size下，这些方法仍倾向于收敛到sharp minimizers上，另一种使得大batch size可行的方案是，使用小batch size先进行warmup，然后再将其调整到预设的batch size。&lt;/p&gt;

&lt;p&gt;另外几个有意思的问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;我们可以证明大的batch size总是会导致深度神经网络收敛到更尖锐的局部最小值吗？&lt;/li&gt;
  &lt;li&gt;在神经网络中，尖锐程度不同的局部最小值的密度分布情况时怎样的？&lt;/li&gt;
  &lt;li&gt;我们可以设计出适合大batch size的神经网络结构吗？&lt;/li&gt;
  &lt;li&gt;是否能够寻找到一种良好的初始化方法，使得大batch size可以应用在普通的神经网络上？&lt;/li&gt;
  &lt;li&gt;是否能够通过算法或者正则化手段，使得能够避开sharp minimizers？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Refs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914&quot;&gt;Recent Advances for a Better Understanding of Deep Learning − Part I&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jeremyjordan.me/nn-learning-rate/&quot;&gt;Setting the learning rate of your neural network&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1712.09913.pdf&quot;&gt;Visualizing the Loss Landscape of Neural Nets&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://icml.cc/Conferences/2018/Schedule?showEvent=2780&quot;&gt;Essentially No Barriers in Neural Network Energy Landscape&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.04836.pdf&quot;&gt;ON LARGE-BATCH TRAINING FOR DEEP LEARNING: GENERALIZATION GAP AND SHARP MINIMA &lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 06 Nov 2020 06:02:23 +0800</pubDate>
        <link>http://localhost:4000//2020/11/%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%92%8Cbatch-size%E8%AE%A8%E8%AE%BA</link>
        <guid isPermaLink="true">http://localhost:4000//2020/11/%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%92%8Cbatch-size%E8%AE%A8%E8%AE%BA</guid>
        
        <category>Machine Learning</category>
        
        <category>Optimization</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>On Sentence Embedding</title>
        <description>&lt;p&gt;This article will briefly introduce some papers on document representation.&lt;/p&gt;

&lt;h2 id=&quot;1-a-simple-but-tough-to-beat-baseline-for-sentence-embeddings&quot;&gt;1. A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS&lt;/h2&gt;

&lt;h3 id=&quot;model&quot;&gt;model&lt;/h3&gt;

&lt;p&gt;This article proposed a method for acquiring sentence embedding called SIF. The method is very simple: for the document collection, first, for each document, the word vector is weighted and averaged with the word frequency as the weight, now we have the representations of each document. Let’s say the number of documents is $D$ and the dimension of the word vector is $E$. Then we get the document set representation matrix $M: D\times E$. Then, perform SVD on the matrix $M$, subtracting its projection in the principal component direction, as the final sentence representation.&lt;/p&gt;

&lt;h3 id=&quot;mathematical-formulation&quot;&gt;mathematical formulation&lt;/h3&gt;

\[v_{s} \leftarrow \frac{1}{|s|} \sum_{w \in s} \frac{a}{a+p(w)} v_{w}\]

\[v_{s} \leftarrow v_{s}-u u^{\top} v_{s}\]

&lt;p&gt;todo: theoretical analysis&lt;/p&gt;

&lt;h2 id=&quot;2-a-structured-self-attentive-sentence-embedding&quot;&gt;2. A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING&lt;/h2&gt;

&lt;p&gt;At present, the research on paragraph/sentence representation is not rich enough comparing with word embeddings. Research on sentence representation is usually divided into two categories:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Sentence-level semantic models trained through unsupervised methods, such as SkipThought, paragraphVector, Recursive auto-encoders, Sequential Denoising Autoencoders (SDAE) FastSent, etc.&lt;/li&gt;
  &lt;li&gt;Obtained through supervised training in specific downstream tasks, involving models such as recurrent networks, recursive networks, and convolutional networks;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This paper proposes a self-attention mechanism for sentences to replace the max/avg pooling operation over tokens at each time step after a traditional RNN layer, and at the same time, it can extract different levels of sentence semantic information.&lt;/p&gt;

&lt;h3 id=&quot;the-proposed-model&quot;&gt;the proposed model&lt;/h3&gt;

&lt;p&gt;The sentence representation model proposed in this article is divided into two parts:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Bidirectional LSTM layer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Self-attention layer&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For sentence: $S=(w_1, w_2, …, w_n)$, where $w_i$ represents the $d$-dimensional word embedding of the $i$-th word. $S$ can be expressed as a matrix $S_{n \times d}$ without any relationship along the rows.&lt;/p&gt;

&lt;p&gt;Then input $S$ into the bidirectional LSTM:&lt;/p&gt;

\[\begin{aligned} \overrightarrow{h_{t}} &amp;amp;=\overrightarrow{L S T M}\left(w_{t}, \overrightarrow{h_{t-1}}\right) \\ \overleftarrow{h_{t}} &amp;amp;=\overleftarrow{L S T M}\left(w_{t}, \overleftarrow{h_{t+1}}\right) \end{aligned}\]

&lt;p&gt;After concat the output of each time step toward the forward and backward directions, the representation matrix $H_{n \times 2u}=(h_1, h_2, …, h_n)$ is obtained, where $u$ is the hidden dimension of LSTM.
Because it is planned to encode the variable-length sequence into a fixed-size representation vector, it is necessary to aggregate the representation vector of each token of the variable-length sequence, attention mechanism is used to calculate the weight of each token. The weight vector calculation method is as follows:&lt;/p&gt;

\[\mathbf{a}=\operatorname{softmax}\left(\mathbf{w}_{\mathbf{s} 2} \tanh \left(W_{s 1} H^{T}\right)\right)\]

&lt;p&gt;$W_{s1}:d_a \times 2u$，$w_{s2}: 1 \times d_a$，$d_a$ is a hyper-parameter.&lt;/p&gt;

&lt;p&gt;At this time, $\mathbf{a}$ is a vector of $1\times n$, which represents the weight of each token in the weighted average process. Perform weighted average for each token in the representation matrix $H$ to get the sentence representation $m$ of $1 \times d$.&lt;/p&gt;

&lt;p&gt;For longer sentences or sentences that contain different descriptions or contexts, sometimes we want to express the sentence from different point of views. In order to achieve this, the author replace the vector $w_ {s2}: 1 \times d_a$ with a matrix $W_{s2}: r\times d_a$, which do the same thing like multi-head attention. Note that at this time softmax should be executed line by line.&lt;/p&gt;

&lt;p&gt;Finally we got the attention score matrix $A: r\times n$, and do the dot product with the representation matrix $H$ to get the final representation matrix $M$ of the sentence:&lt;/p&gt;

\[M=AH\]

&lt;h3 id=&quot;penalty-term&quot;&gt;penalty term&lt;/h3&gt;

&lt;p&gt;In order to avoid the loss of diversity of multi-head attention, a penalty item needs to be added to the matrix $A$. The author found in the experiment that using KL divergence to measure the diversity between weights is not stable (a large number of items are close to 0 in $A$ after softmax, This leads to numerical instability in the calculation of KL divergence). In addition, it is obvious that KL divergence cannot be achieved if we want each row vector to focus on a single characteristic as much as possible. The author used the following penalties:&lt;/p&gt;

\[P=\left\|\left(A A^{T}-I\right)\right\|_{F}^{2}\]

&lt;p&gt;This penalty item will be minimized together with loss of downstream tasks during traing.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;summary&lt;/h3&gt;

&lt;p&gt;The advantage of the method proposed in this paper is that it can force the attention to be calculated from different angles during the training process, and it can overcome the problem of long-distance dependence to a certain extent. The disadvantage is that this method is relatively dependent on downstream tasks, and can only be trained in a supervised manner, and has limited compatibility between different tasks.&lt;/p&gt;

&lt;h2 id=&quot;3-distributed-representations-of-sentences-and-documents&quot;&gt;3. Distributed Representations of Sentences and Documents&lt;/h2&gt;

&lt;p&gt;The shortcomings of the current method of obtaining sentence embedding:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bag-of-words model
    &lt;ul&gt;
      &lt;li&gt;lost order info&lt;/li&gt;
      &lt;li&gt;less semantic&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;bag-of-n-grams&lt;/li&gt;
  &lt;li&gt;data sparsity&lt;/li&gt;
  &lt;li&gt;high-dimensionality&lt;/li&gt;
  &lt;li&gt;less semantic&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This paper proposes an unsupervised sentence embedding training method for variable length text: Paragraph Vector.&lt;/p&gt;

&lt;p&gt;There are two training methods for Paragraph Vector:&lt;/p&gt;

&lt;h3 id=&quot;1-a-distributed-memory-model&quot;&gt;1. A distributed memory model&lt;/h3&gt;

&lt;p&gt;For corpus C, suppose it contains $N$ paragraphs, and the embedding dimension of each paragraph is $p$; the corpus contains $M$ words, and the embedding dimension of each word is $q$; The number of parameters the model needs to learn is $N \times p + M \times q$, each paragraph is mapped to a paragraph id (that is, we can treat paragraphs in the corpus as special words).&lt;/p&gt;

&lt;p&gt;During the training, for a paragraph, we select a sliding window W. The text in the window is called context, which is the basic unit of training. The context in the same paragraph shares the paragraph embedding, and the words in the entire corpus share words embedding. For context C, use its paragraph vector to concatenate the word embedding of each word in C to predict what the next word of this context is.&lt;/p&gt;

&lt;p&gt;At prediction time, for the set of paragraphs to be predicted ${P}_{n}$, first, add it to corpus C (that is, add $n$ rows to the paragraph matrix),  then continue to execute the training process on new corpus until convergence, with word embedding fixed.&lt;/p&gt;

&lt;p&gt;In this training method, the paragraph vector plays a memory role of the topic and other information of the paragraph, so it is called PV-DM (Distributed Memory Paragraph Vectors).&lt;/p&gt;

&lt;h3 id=&quot;2-distributed-bag-of-words&quot;&gt;2. Distributed bag of words&lt;/h3&gt;
&lt;p&gt;Another method of PV training is as follows, which is similar to training the skip-gram model in Word2vec. In the training process, a window W is sampled from the paragraph P, and given the paragraph vector of the paragraph to which the window belongs, predict the random sampling word w from the window. This method named PV-DBOW because it ignores the order of words.&lt;/p&gt;

&lt;p&gt;Experimental results show that combining the sentence vectors obtained by these two methods can get more stable and better results.&lt;/p&gt;

&lt;h3 id=&quot;futher-observations&quot;&gt;futher observations&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;The effect of PV-DM is better than PV-DBOW&lt;/li&gt;
  &lt;li&gt;In PV-DM, concat paragraph vectors and word embedding could achive better result&lt;/li&gt;
  &lt;li&gt;The selection of window size requires cross-validation&lt;/li&gt;
  &lt;li&gt;The time cost to obtain the paragraph vector is high, but this problem can be alleviated by parallel computing.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Refs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://openreview.net/pdf?id=SyK00v5xx&quot;&gt;1. A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/PrincetonML/SIF/blob/master/src/SIF_embedding.py&quot;&gt;2. Implementation of SIF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.03130&quot;&gt;3. A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cn.arxiv.org/pdf/1405.4053.pdf&quot;&gt;4. Distributed Representations of Sentences and Documents&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 25 Sep 2020 07:34:18 +0800</pubDate>
        <link>http://localhost:4000//2020/09/On-Sentence-Embedding</link>
        <guid isPermaLink="true">http://localhost:4000//2020/09/On-Sentence-Embedding</guid>
        
        <category>Deep Learning</category>
        
        <category>Embedding</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>多模态学习</title>
        <description>&lt;p&gt;多模态学习旨在搭建能够处理多种模态信息的模型，文章&lt;a href=&quot;https://arxiv.org/pdf/1705.09406.pdf&quot;&gt;Multimodal Machine Learning: A Survey and Taxonomy &lt;/a&gt; 从表示（Representation）、翻译（Translate）、对齐（Alignment）、融合（Fusion）、协同学习（Co-learning）等几个方面对多模态学习进行综述。重点关注语言、图像和声音三种模态。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;表示（representation）：各种模态是异质的（如文本通常基于符号表示，而声学和视觉信息往往通过信号表示），构造使得不同模态信息能够互相融合、摒弃冗余信息的信息表达方式是至关重要的。&lt;/li&gt;
  &lt;li&gt;翻译（translation）：多种模态之间的对应关系开放性、主观性较强，模态间的映射常常不止一种方式，思考：用一段话描述一张图片，有几种方式？&lt;/li&gt;
  &lt;li&gt;对齐（alignment）：模态间的信息需要进行对其，用以确定不同模态内的元素的直接关系&lt;/li&gt;
  &lt;li&gt;融合（fusion）：在实际运用中，应寻找合理的多模态信息融合方式，以最大化多模态共同预测时的效率和准确率&lt;/li&gt;
  &lt;li&gt;协同学习（co-learning）：在某一种模态资源有限时，通过资源丰富的另一种模态辅助训练，以达到多个模态的模块协同训练的目的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;回顾多模态模型的应用历史&quot;&gt;回顾多模态模型的应用历史&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;AVSR：（Audio-visual speech recognition）：原本意在通过视觉信息提高语言识别准确率，实验发现视觉信息在语音信息包含噪声较多时变得重要，这一试验表明视觉信息和语音信息这两种模态之间有一定的信息交互；&lt;/li&gt;
  &lt;li&gt;多媒体信息检索：互联网上各种模态信息增长趋势迅猛，需要开发能够直接进行多模态信息检索的模型，来逐渐取代单纯的基于关键词的信息检索方式。一个优秀的数据集：MED（multimedia event detection）；&lt;/li&gt;
  &lt;li&gt;人类多模态交互理解：21世纪初逐渐兴起，数据集有：AMI Meeting Corpus 、SEMAINE corpus，比赛：AVEC challenge；&lt;/li&gt;
  &lt;li&gt;最近兴起了语言和视觉两种模态融合的任务，如image captioning（图像描述），这一任务的难点在于模型的评价，VQA任务通过图片提问的方式尝试解决这个问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;representations&quot;&gt;representations&lt;/h2&gt;

&lt;p&gt;多模态表达面临以下几个问题：如何融合多种模态的特征？如何处理不同层级的噪声？如何处理缺失的模态？Bengio认为，一个好的表示，应具有以下特点：平滑性（smoothness），时空一致性（temporal and spatial coherence），稀疏性（sparsity），聚集性（natural clustering amongst others）；至于多模态表达，Srivastava and Salakhutdinov提出，表示空间中的相似表达应能够反映不同模态所包含的概念的相似程度；多模态的表征应是易于获取的，即便某些模态数据缺失，并且，其余模态数据应能够“推理”出缺失模态的表达。&lt;/p&gt;

&lt;p&gt;至3&lt;/p&gt;

&lt;h2 id=&quot;论文笔记&quot;&gt;论文笔记&lt;/h2&gt;
&lt;p&gt;多模态学习是深度学习领域中一个比较热门的方向，本文记录一下这个方向的相关论文，方便参考。&lt;/p&gt;

&lt;h3 id=&quot;1-one-model-to-learn-them-all&quot;&gt;1. one model to learn them all&lt;/h3&gt;

&lt;p&gt;本文提出了一个多模态模型，将8个任务融合在一个模型中，具体包含：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Parsing&lt;/li&gt;
  &lt;li&gt;Speech recognization&lt;/li&gt;
  &lt;li&gt;ImageNet classification&lt;/li&gt;
  &lt;li&gt;Image caption&lt;/li&gt;
  &lt;li&gt;Translation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;模型在各个任务上都取得了不错的效果，部分超过了一些新模型（虽然还没有达到sota水平）。&lt;/p&gt;

&lt;p&gt;作者认为，本文有两个主要贡献（对多模态网络至关重要的两点）：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;信息通过各个模态相关的小型网络转换到一个通用的中间形态，再由该中间形态通过不同的模态网络转化为输出
    &lt;ul&gt;
      &lt;li&gt;中间表示层的尺度是可变的&lt;/li&gt;
      &lt;li&gt;同一领域下，不同任务共享模态网络&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;各种任务对各个子计算模块的重要性依赖程度不同（如，attention机制在翻译任务中的重要程度高于其在image caption任务中的影响）&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;模型结构&quot;&gt;模型结构&lt;/h4&gt;

&lt;p&gt;模型的整体结构分为三部分：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;encoder&lt;/li&gt;
  &lt;li&gt;I/O Mixer&lt;/li&gt;
  &lt;li&gt;AR decoder&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在encoder和decoder中，主要包含以下计算组件（computational blocks）：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conv&lt;/p&gt;

    &lt;p&gt;局部特征捕获，使用depthwise separable conv&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;attention layer&lt;/p&gt;

    &lt;p&gt;关注重要的特征&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;稀疏门限模块集成（Sparsely-gated mixture-of-experts）&lt;/p&gt;

    &lt;p&gt;在保证计算复杂度的前提下，增大模型容量，由一系列前馈网络和可训练的门限网络构成，负责从各个输入中选择稀疏的组合&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;为了适应各个任务的形态，本文提出了一些任务相关的子网络（模态网络，Modality-nets），主要包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;语言模态网络&lt;/li&gt;
  &lt;li&gt;图像模态网络&lt;/li&gt;
  &lt;li&gt;类别模态网络（Categorical modality net）&lt;/li&gt;
  &lt;li&gt;语音模态网络&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;实验部分&quot;&gt;实验部分&lt;/h4&gt;

&lt;p&gt;实验部分，本文回答了三个问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;本文提出的MultiModel在8个子任务上，离sota还有多远？&lt;/p&gt;

    &lt;p&gt;看论文结果，应该还是有一段距离，作者表示由于没有仔细调参，当前多模态模型的结果还无法超越经过细致调参的传统模型。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;同时训练8个子任务，与分别训练有什么差别？&lt;/p&gt;

    &lt;p&gt;在训练多模态模型的同时 ，作者在同等条件下同时训练了独立的模型，实验结果表明多模态联合训练时的结果与独立训练各个任务相似，在个别任务上甚至有一些提升，训练数据越少的任务，提升通常会越明显。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不同的计算组件（computational blocks）在子任务上的影响如何？&lt;/p&gt;

    &lt;p&gt;这些组件的存在，至少不会带来子任务性能的下降。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;多模态网络设计的要点在于，任务间能够共享的参数尽量要在模态间共享，这有助于不同模态之间表示空间的统一，同时也能降低task-specific的参数量，控制模型的尺寸。&lt;/p&gt;

&lt;p&gt;Refs.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1610.02357&quot;&gt;Depthwise separable conv&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1701.06538&quot;&gt;Outrageously large neural networks: The sparsely-gated mixture-of-experts layer&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.05137.pdf&quot;&gt;One model to learn them all&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Wed, 23 Sep 2020 06:35:01 +0800</pubDate>
        <link>http://localhost:4000//2020/09/Multi-Modal-Learning</link>
        <guid isPermaLink="true">http://localhost:4000//2020/09/Multi-Modal-Learning</guid>
        
        <category>Multi-modal Learning</category>
        
        <category>Deep Learning</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>MLE &amp; MAP</title>
        <description>&lt;p&gt;绝大部分机器学习的优化过程最终都会转化为求目标函数最值的过程，MLE（Maximum Likelihood Estimation，最大似然估计）和MAP（Maximum A Posteriori，最大后验估计）是两种生成目标函数的思想。下文尝试讨论MLE和MAP的区别和联系。&lt;/p&gt;

&lt;p&gt;MLE仅通过观测样本对参数进行估计，MLE的目标函数为$\arg\max P(D\mid \theta)$，而MAP不仅通过观测的样本，同时也通过先验（priori）进行参数的估计，其目标函数为$\arg \max P(\theta \mid D)$。&lt;/p&gt;

&lt;h1 id=&quot;最优化map&quot;&gt;最优化MAP&lt;/h1&gt;

\[\begin{aligned} \arg\max P(\theta \mid D) &amp;amp;= \arg\max P(D\mid\theta) \cdot P(\theta)\\ &amp;amp;=\arg\max \log P(D\mid \theta) + \log P(\theta) \end{aligned}\]

&lt;p&gt;由上式可以看出，MAP的目标函数的第一项为MLE的目标函数，第二项$\log(\theta)$相当于优化MAP的过程中，对MLE目标函数施加的正则化项，下文将证明，随着$\theta$分布的不同，正则化项的类型也不同。&lt;/p&gt;

&lt;p&gt;下文以Logistic Regression为例：&lt;/p&gt;

\[\begin{aligned} objective\ of\ MAP &amp;amp;= \arg\max P(\theta \mid D) \\ &amp;amp;=\arg\max P(D\mid \theta) \cdot P(\theta) \\ &amp;amp;=\arg\max \log P(D\mid \theta) + \log P(\theta) \\&amp;amp;=\arg\max \sum_\limits{i=1}^n \log P(y_i\mid x_i;\theta) + \log P(\theta)  \end{aligned}\]

&lt;h1 id=&quot;从高斯先验到l_2正则&quot;&gt;从高斯先验到$L_2$正则&lt;/h1&gt;

&lt;p&gt;假设参数$\theta$服从高斯分布：&lt;/p&gt;

\[\begin{aligned}logP(\theta)&amp;amp;=log(\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{\theta^2}{2\sigma^2})) \\&amp;amp;=-log(\sqrt{2\pi}\sigma) - \frac{\theta^2}{2\sigma^2}  \end{aligned}\]

&lt;p&gt;则MAP的目标函数可写作：&lt;/p&gt;

\[\begin{aligned} objective\ of\ MAP &amp;amp;=\arg\max \sum_\limits{i=1}^n \log P(y_i\mid x_i;\theta) -log(\sqrt{2\pi}\sigma) - \frac{\theta^2}{2\sigma^2} \\&amp;amp;=\arg\max \sum_\limits{i=1}^n \log P(y_i\mid x_i;\theta)-\frac{1}{2\sigma^2}\Vert \theta \Vert_2^2 \end{aligned}\]

&lt;p&gt;即：当参数服从高斯分布时，MAP目标函数中的$\log P(\theta	)$项相当于对MLE目标函数施加的$L_2$正则。&lt;/p&gt;

&lt;h1 id=&quot;从拉普拉斯先验到l_1正则&quot;&gt;从拉普拉斯先验到$L_1$正则&lt;/h1&gt;

&lt;p&gt;假设参数$\theta \sim Laplace(\mu,b),\mu=0$，则：$P(\theta)=\frac{1}{2b}exp(-\frac{\vert\theta\vert}{b})$&lt;/p&gt;

\[\begin{aligned} \log P(\theta)&amp;amp;=\log(\frac{1}{2b}exp(-\frac{\vert\theta\vert}{b})) \\&amp;amp;=log(\frac{1}{2b})-\frac{\vert\theta\vert}{b}\end{aligned}\]

&lt;p&gt;MAP的目标函数可写作：&lt;/p&gt;

\[\begin{aligned} objective\ of\ MAP &amp;amp;=\arg\max \sum_\limits{i=1}^n \log P(y_i\mid x_i;\theta)  -\frac{1}{b}\Vert\theta\Vert_1  \end{aligned}\]

&lt;p&gt;即：当参数服从拉普拉斯分布时，MAP目标函数中的$\log P(\theta	)$项相当于对MLE目标函数施加的$L_1$正则。&lt;/p&gt;

&lt;p&gt;上述推导以LR为例验证了“Adding Priori is Equivalent to Regularization”的结论，事实上，在MLE的框架下，上述结论可推广至任何模型。&lt;/p&gt;

&lt;h1 id=&quot;map-approaches-to-mle-solution&quot;&gt;MAP approaches to MLE solution&lt;/h1&gt;

&lt;p&gt;回顾MAP的目标函数：&lt;/p&gt;

\[\begin{aligned} objective\ of\ MAP =\arg\max \sum_\limits{i=1}^n \log P(y_i\mid x_i;\theta) + \log P(\theta)  \end{aligned}\]

&lt;p&gt;目标函数的第一部分是一个概率加项，第二项仅与模型的参数有关，当样本数量趋于无限大，即$n \to \infty$时，正则化项的影响减弱至无，此时MAP退化为MLE。&lt;/p&gt;

&lt;h1 id=&quot;ref&quot;&gt;Ref.&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~aarti/Class/10701_Spring14/slides/MLE_MAP_Part1.pdf&quot;&gt;1. CMU-10701:2. MLE, MAP, Bayes classification&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 16 Aug 2020 17:35:03 +0800</pubDate>
        <link>http://localhost:4000//2020/08/MAP&MLE</link>
        <guid isPermaLink="true">http://localhost:4000//2020/08/MAP&MLE</guid>
        
        <category>Machine Learning</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>Derivation of EM</title>
        <description>&lt;p&gt;隐变量模型（Latent Variable Models）指模型中包含不可观测的隐含变量$z$，隐变量模型的求解根据$z$的已知与否分为两类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;complete case&lt;/li&gt;
  &lt;li&gt;incomplete case&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;complete case是指求解过程中，$(x,z)$均已知，此类模型求解可以使用MLE等方法进行求解；incomplete case中，隐变量$z$是未知的，求解该类模型需要使用EM算法。&lt;/p&gt;

&lt;p&gt;下文对EM算法进行简单的推导，假设因变量模型相关的参数和变量分别为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\theta$：model parameters&lt;/li&gt;
  &lt;li&gt;$x$：observed variable&lt;/li&gt;
  &lt;li&gt;$z$：latent variable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Objective: $L(\theta)= \ln p(x\mid \theta)$，优化目标为：$\arg \max L(\theta)=\arg \max \ln p(x\mid\theta)$&lt;/p&gt;

&lt;p&gt;记EM算法经过$n$轮迭代后的参数为$\theta_n$，目标函数也可以写成如下的形式，即在第$n$次迭代的基础上，最大化当前的目标函数和第$n$轮目标函数的差值：&lt;/p&gt;

\[\begin{aligned} \arg \max _{\theta} L(\theta)-L\left(\theta_{n}\right) &amp;amp;=\ln p(x \mid \theta) -\ln p\left(x \mid \theta_{n}\right) \\ &amp;amp;=\ln \sum_{z} p(x, z \mid \theta)-\ln p\left(x \mid \theta_{n}\right) \\ &amp;amp;=\ln \sum_{z} p(x \mid z, \theta) \cdot p(z \mid \theta)-\ln p\left(x \mid \theta_{n}\right) \\ &amp;amp;=\ln \sum_{z} p\left(x \mid z, \theta\right) \cdot p(z \mid \theta) \cdot \frac{p\left(z \mid x, \theta_{n}\right)}{p\left(z \mid x, \theta_{n}\right)}-\ln p\left(x \mid \theta_{n}\right) \\ &amp;amp;=\ln \sum_{z} p\left(z \mid x, \theta_{n}\right) \cdot \frac{p(x \mid z, \theta) \cdot p(z \mid \theta)}{p\left(z \mid x, \theta_{n}\right)}-\ln p\left(x \mid \theta_{n}\right) \end{aligned}\]

&lt;p&gt;$\log\sum$项在求梯度过程中不方便计算，这里引入Jensen不等式：$\ln\sum_\limits{i=1}^{n}\lambda_i x_i \geqslant \sum_\limits{i=1}^{n}\lambda_i\ln x_i \quad s.t. \sum_\limits{i=1}^{n}\lambda_i=1$&lt;/p&gt;

&lt;p&gt;由于$\sum_\limits{z} p(z\mid x,\theta_n)=1$，可将该项视为Jensen不等式中的$\lambda$，因此有：&lt;/p&gt;

&lt;p&gt;$\arg\max L(\theta)-L(\theta_n) \geqslant \sum_{z} p\left(z \mid x, \theta_{n}\right) \ln \frac{p\left(x \mid z, \theta\right) \cdot p(z \mid \theta)}{p\left(z \mid x, \theta_{n}\right)}-\ln p\left(x \mid \theta_{n}\right)$&lt;/p&gt;

&lt;p&gt;至此，得到：&lt;/p&gt;

\[\begin{aligned} L(\theta)-L(\theta_n) &amp;amp; \geqslant \sum_{z} p\left(z \mid x, \theta_{n}\right) \ln \frac{p\left(x \mid z, \theta\right) \cdot p(z \mid \theta)}{p\left(z \mid x, \theta_{n}\right)}-\ln p\left(x \mid \theta_{n}\right) \\ &amp;amp;=\sum_{z} p\left(z \mid x, \theta_{n}\right) \ln \frac{p(x\mid z,\theta) \cdot p(z\mid \theta)}{p(x\mid x,\theta_n) \cdot p(x\mid \theta_n)} \\&amp;amp;=\Delta(\theta\mid\theta_n) \end{aligned}\]

&lt;p&gt;即：$L(\theta)\geqslant L(\theta_n) +\Delta(\theta\mid\theta_n)$，此时最大化$L(\theta)$等价于最大化$L(\theta)$的下界，因此，下一轮迭代的最优$\theta_{n+1}$可以表示为：&lt;/p&gt;

\[\begin{aligned} \theta_{n+1} &amp;amp;=a r g \max _{\theta} L\left(\theta_{n}\right)+\Delta\left(\theta \mid \theta_{n}\right) \\ &amp;amp;=\arg \max _{\theta} \Delta\left(\theta \mid \theta_{n}\right) \\ &amp;amp;=\arg \max _{\theta} \sum_{z} p\left(z \mid x, \theta_{n}\right) \ln p(x \mid z, \theta) \cdot p(z \mid \theta) \\ &amp;amp;=\arg \max _{\theta} \sum_{z} p\left(z \mid x, \theta_{n}\right) \ln p(x, z \mid \theta) \\ &amp;amp;=\arg \max _{\theta} E_{z \mid x, \theta_{n}} p(x, z \mid \theta)\end{aligned}\]

&lt;p&gt;其中，$E_{z \mid x, \theta_{n}} p(x, z \mid \theta)$为$(z\mid x,\theta,n)$的期望，由于该项中包含了两个未知变量$\theta,z$，最大化过程分为两步进行：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;E-step：根据当前的$\theta$计算出$z$的期望（在包含两个待求解变量时，E-step固定其中的$\theta$来独立求解$z$，因此EM算法中的E-step可以看作是coordinate decent的一种特例。）&lt;/li&gt;
  &lt;li&gt;M-step：$maximize \ln p(x,z\mid \theta)$（可以认为此时的$z$是已知的，这种comlelte-case可以直接使用MLE等优化方法求解。）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;迭代执行上述两步，直至收敛，便可以得到最终需要求解的参数$\theta$。&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Aug 2020 01:16:03 +0800</pubDate>
        <link>http://localhost:4000//2020/08/Derivation-of-EM</link>
        <guid isPermaLink="true">http://localhost:4000//2020/08/Derivation-of-EM</guid>
        
        <category>Machine Learning</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>正则化</title>
        <description>&lt;p&gt;在机器学习中，模型的训练过程即是在寻找一个&lt;strong&gt;足够好&lt;/strong&gt;的函数$F^{\star}$，使得$F^{\star}$在训练数据和未来的新数据上都具有良好的推理效果。为了从候选函数空间${F}$选择“好”的模型，人们引入损失函数的概念。一般地，对于样本$(x, y)$和模型$F$，假设模型对样本的预测值为$\hat{y}$，则损失函数被定义在$\mathbb{R}$的函数$l(y, \hat{y})$，用于描述预测值和真值的差距。&lt;/p&gt;

&lt;p&gt;一般地，损失函数是一个有下确界的函数，这样，机器学习的优化过程即转化为了在数据集上的损失函数最小化问题。到目前为止，损失函数仅考虑了在训练数据上的经验风险，仅考虑经验风险，很有可能导致参数空间过于复杂，造成模型对训练数据过拟合。&lt;/p&gt;

&lt;h2 id=&quot;模型复杂度&quot;&gt;模型复杂度&lt;/h2&gt;

&lt;p&gt;过拟合现象、泛化能力和模型复杂度三者之间联系紧密，模型复杂度取决于：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;模型本身的选择&lt;/li&gt;
  &lt;li&gt;模型参数个数&lt;/li&gt;
  &lt;li&gt;模型的参数空间选择（当模型和参数个数都确定时，仍可以使用一些手段（如正则化），从参数空间中选择较优的参数）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当模型的复杂程度相对训练数据量过高时，就会发生过拟合现象，减轻过拟合现象的措施有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用更简单的模型&lt;/li&gt;
  &lt;li&gt;减少参数&lt;/li&gt;
  &lt;li&gt;在搜索参数空间时加入限制（如对参数增加正则化）&lt;/li&gt;
  &lt;li&gt;获取更多的样本&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文仅讨论使用正则化手段减轻过拟合的影响。&lt;/p&gt;

&lt;h2 id=&quot;引入正则化&quot;&gt;引入正则化&lt;/h2&gt;

&lt;p&gt;为了减轻模型的过拟合趋势，我们需要对损失函数中加入描述模型复杂程度的正则项$\Omega(F)$，优化过程转化为：&lt;/p&gt;

\[F^\star:=\mathop{\arg\min}_\limits{\theta} Obj(F)=\mathop{\arg\min}_\limits{\theta}(L(F)+\gamma\Omega(F)),\gamma&amp;gt;0\]

&lt;p&gt;目标函数$Obj(\cdot)$描述模型的结构风险，其中$L(F)$表示模型在训练数据上的损失，$\Omega(F)$为正则化项，$\gamma$用于控制正则化项的强度，一般使用$L_p$范数作为正则项，用于对参数光滑度和参数空间范数上界进行限制，提升模型的泛化能力。&lt;/p&gt;

&lt;p&gt;常见的用于正则化的$L_p$范数有以下几种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$L_0: \Vert W \Vert_0=\sum\limits^{d}_{i=1}I(w_i\neq 0)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;$L_1: \Vert W \Vert_1=\sum\limits^{d}_{i=1}\vert w_i \vert$&lt;/li&gt;
  &lt;li&gt;$L_2: \Vert W \Vert_2=\sum\limits^{d}_{i=1} w_i^2$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;常用$L_1$和$L_2$正则化来限制模型的复杂度。&lt;/p&gt;

&lt;h2 id=&quot;l_1和l_2正则化&quot;&gt;$L_1$和$L_2$正则化&lt;/h2&gt;

&lt;p&gt;从概率角度考虑，对模型参数施加的正则化项其实就是引入了参数的先验，$L_1$正则化对应Laplace先验，$L_2$正则对应高斯先验。这两种正则化都可以使参数变“小”。不同之处在于，$L_1$正则化可以使得参数稀疏化，可以用于特征选择；$L_2$正则化可以使得参数尺度受到约束，减轻过拟合现象。我们可以根据场景选择合适的正则化项，甚至可以同时使用二者，如stanford提出的ElasticNet就同时在模型中使用了$L_1$和$L_2$正则化，参考这篇1.2w次引用的&lt;a href=&quot;https://web.stanford.edu/~hastie/TALKS/enet_talk.pdf&quot;&gt;slide&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;l_2正则化能够通过减小参数尺度来减弱模型过拟合现象的原因&quot;&gt;$L_2$正则化能够通过减小参数尺度来减弱模型过拟合现象的原因&lt;/h2&gt;

&lt;p&gt;如果参数尺度很大，则对输入施加一个微小的扰动就会引起目标函数发生较大幅度的变化，也即模型对输入噪声的鲁棒性变差，过拟合风险增加。&lt;/p&gt;

&lt;h2 id=&quot;l_1能够使模型参数变得稀疏的原因&quot;&gt;$L_1$能够使模型参数变得稀疏的原因&lt;/h2&gt;

&lt;p&gt;下面以线性回归为例，简单分析$L_1$正则化会产生稀疏解的原因。&lt;/p&gt;

&lt;p&gt;在线性回归中，如果加入$L_2$正则，则一般称为岭回归（Ridge regression）；如果加入$L_1$正则，则一般称为Lasso回归。因此，$L_1$正则有时候也被称为Lasso正则。&lt;/p&gt;

&lt;p&gt;Lasso回归的目标函数为：&lt;/p&gt;

\[L=\Vert XW-Y \Vert_F^2 + \lambda\Vert W \Vert_1\]

&lt;p&gt;由于$ \Vert W \Vert_1=\sum\limits^{d}_{i=1}\vert w_i \vert$是一个包含局部不可导点的函数，因此，在优化过程中，不能使用常规的优化算法（如梯度下降法）。&lt;/p&gt;

&lt;p&gt;有很多特殊的优化算法可以解决这一类优化问题，如LARS、Parallel CD、ADMM、Coordinate Descent等。Coordinate descent属于Sub-gradient descent范畴，以下介绍使用其进行参数求解。Coordinate descent的运行流程可以简化为：&lt;/p&gt;

&lt;p&gt;循环执行以下直至收敛：&lt;/p&gt;

&lt;p&gt;​        选择一个参数维度$i$&lt;/p&gt;

&lt;p&gt;​        固定其余维度的参数&lt;/p&gt;

&lt;p&gt;​        在第$i$维度上执行参数更新：$w_i\leftarrow w_i-\frac{\partial L}{\partial w_i}(W)$&lt;/p&gt;

\[Obj:L=\sum_\limits{i=1}^{n}\left(\sum_\limits{j=1}^{d} w_{j} x_{ij}+b-y_{i}\right)^{2}+\sum_\limits{j=1}^{d}\vert w_{j} \vert\]

\[\begin{aligned} \frac{\partial L}{\partial w_{l}} &amp;amp;=2 \sum_{i=1}^{n}\left(\sum_{j=1}^{d} w_{j} x_{i j}+b-y_{i}\right) \cdot x_{i l}+\frac{\partial\left|w_{l}\right|}{\partial w_{l}} \\ &amp;amp;=2 \sum_{i=1}^{n}\left(\sum_{j=1 \atop j\neq l}^{d} w_{j} x_{i j}+b-y_{i}+w_{l} x_{i l}\right) \cdot x_{i l}+\frac{\partial \vert w_{l}\vert}{\partial w_{l}} \\ &amp;amp;=2 \sum_{i=1}^{n}\left(\sum_{j=1 \atop j \neq l}^{d} w_{j} x_{i j}+b-y_{i}\right) \cdot x_{i l}+2 \sum_{i=1}^{n} w_{l} x_{il}^{2}+\frac{\partial \vert w_{l} \vert }{\partial w_{l}} \\ &amp;amp;=2 \sum_{i=1}^{n}\left(\sum_{j=1 \atop j \neq l}^{d} w_{j} x_{i j}+b-y_{i}\right) \cdot x_{i l}+2 w_{l} \sum_{i=1}^{n} x_{i l}^{2}+\frac{\partial \vert w_{l} \vert}{\partial w_{l}}\end{aligned}\]

&lt;p&gt;设常数$2 \sum_\limits{i=1}^{n}\left(\sum_\limits{j=1 \atop j \neq l}^{d} w_{j} x_{i j}+b-y_{i}\right) \cdot x_{i l}$为$C_L$；设$2\sum_\limits{i=1}^{n} x_{i l}^{2}$为$a_L$，（$a_L \gt 0$）。&lt;/p&gt;

&lt;p&gt;则$\frac{\partial L}{\partial w_{l}}=C_{L}+w_{L} a_{l}+\lambda \cdot \frac{\partial \vert W_{l} \vert}{\partial l}$，分情况讨论：&lt;/p&gt;

\[\frac{\partial L}{\partial w_{l}}=\left\{\begin{array} \\C_{L}+a_Lw_l+\lambda&amp;amp;,w_l&amp;gt;0   \\ [C_L-\lambda,C_L+\lambda]&amp;amp;,w_l=0 &amp;amp;\\ C_L+a_Lw_l-\lambda&amp;amp;,w_l&amp;gt;0                  \end{array}   \right.\]

&lt;p&gt;令$\frac{\partial L}{\partial w_{l}}=0$，可得：&lt;/p&gt;

\[\hat{w_l}=\left\{ \begin{array}\\ -C_L-\lambda &amp;amp;,if\ C_L\lt -\lambda\\ 0 &amp;amp;,if\ -\lambda \le C_L \le \lambda \\ \lambda-C_L &amp;amp;,if\ C_L\gt \lambda\end{array}\right.\]

&lt;p&gt;由此可见，在更新第$l$维的权重时，当$-\lambda \le C_L \le \lambda$时，权重会被强制置为0，处于此范围的$C_L$导致了参数的稀疏化。&lt;/p&gt;

&lt;h2 id=&quot;正则化做了什么&quot;&gt;正则化做了什么&lt;/h2&gt;

&lt;p&gt;在参数优化过程中加入正则化，实际上是在一个确定的参数空间中，对参数的可行空间（feasible region）作了进一步约束，因此，假设$L$为模型在训练样本上的损失函数，我们可以得到如下结论：&lt;/p&gt;

\[L(\hat{w}_{without\ reg}) \leq L(\hat{w}_{with\ reg})\]

&lt;p&gt;即，加入正则化后的参数在训练数据上的损失，一定不小于无正则化时的。&lt;/p&gt;

&lt;h2 id=&quot;正则化的灵活运用&quot;&gt;正则化的灵活运用&lt;/h2&gt;

&lt;p&gt;以简化的大脑神经元模型为例，假设大脑分为若干个区域（region），每个区域均包含一些神经元，每个神经元均具有对应的参数，$w_{ir_j}$表示大脑第$i$个神经元区域的第$j$个神经元的权重。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://shihanmax.top/20201013230655_vEOXrf_%E6%88%AA%E5%B1%8F2020-10-13%2023.06.38.jpeg&quot; alt=&quot;neu&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;设目标函数为$f(W)$，我们期望通过正则化手段，将以下两个假设考虑进来：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;某一个区域内，仅有少量神经元被激活&lt;/li&gt;
  &lt;li&gt;在空间上相近的神经元，作用类似&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;则我们可以构造如下优化目标：&lt;/p&gt;

\[\mathop{minimize}: f(W)+\sum\limits_{i=1}^R \lambda_i\Vert w
_{i \cdot}\Vert_1+\sum\limits_{i=1}^{R}\sum\limits_{j=1}^{r_i}\lambda_2\Vert w_{ij}-w_{ij-1}\Vert_2\]

&lt;p&gt;在上式中，$R$表示神经元区域个数，$r_k$表示第$k$个区域中包含的神经元个数，我们引入了两个正则化项，第一个用于神经元区域内的稀疏化，第二个用于约束相近神经元区域的相似程度。&lt;/p&gt;

&lt;h2 id=&quot;ref&quot;&gt;Ref&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.greedyai.com&quot;&gt;Wenzhe Li, Greedy AI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://web.stanford.edu/~hastie/TALKS/enet_talk.pdf&quot;&gt;Elastic Net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/正则化_(数学)&quot;&gt;wikipedia: 正则化&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_norm&quot;&gt;wikipedia: matrix norm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cs.cmu.edu/~ggordon/10725-F12/slides/25-coord-desc.pdf&quot;&gt;CMU: Coordinate Descent&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 05 Aug 2020 05:34:18 +0800</pubDate>
        <link>http://localhost:4000//2020/08/%E6%AD%A3%E5%88%99%E5%8C%96</link>
        <guid isPermaLink="true">http://localhost:4000//2020/08/%E6%AD%A3%E5%88%99%E5%8C%96</guid>
        
        <category>Machine Learning</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>序列标注实践</title>
        <description>&lt;p&gt;序列标注问题是一类典型的NLP问题，具体应用有：分词、词性标注、命名实体识别等。&lt;/p&gt;

&lt;p&gt;序列标注问题的定义是：给定序列$S$，期望通过模型M得到序列中每一个token对应的标签序列$Z$，这里定义，$S$中每个词token的可能情况有$n_{word}$中，标签序列$Z$中的每一个标签tag的可能情况有$n_{tag}$种。&lt;/p&gt;

&lt;p&gt;本文从噪声信道模型的角度对序列标注问题进行建模，并通过维特比算法优化最优路径的搜索。&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;定义：$S=w_1w_2w_3…w_{N}$，对应的任一种标签序列为$Z=z_1z_2z_3…z_{N}$，目标是寻找最优的标签序列$\hat{Z}$。&lt;/p&gt;

\[\begin{equation}\begin{aligned}  \hat{Z}&amp;amp;=\mathop{argmax}_\limits{z}(P(Z\vert S)) \\&amp;amp;=\mathop{argmax}_\limits{z}(P(S\vert Z)\cdot P(Z)) \\&amp;amp;=\mathop{argmax}_\limits{z}(P(w_1w_2...w_N\vert z_1z_2...z_N) \cdot  P(z_1z_2...z_N))   \end{aligned}  \end{equation}\]

&lt;p&gt;上式中乘积的第一项为Translation model（TM）、第二项为Language model（LM）。&lt;/p&gt;

&lt;p&gt;在TM中引入独立假设，在LM中引入bi-gram假设，可得：&lt;/p&gt;

\[\hat{Z}=\mathop{argmax}_\limits{z}( \prod_\limits{i=1}^{N}P(w_i\vert z_i)\cdot P(z_1)\cdot \prod_\limits{j=2}^N P(z_j\vert z_{j-1}))\]

&lt;p&gt;对概率进行对数化：&lt;/p&gt;

\[\hat{Z}=\mathop{argmax}_\limits{z}( \sum_\limits{i=1}^{N} logP(w_i\vert z_i)+ log P(z_1)+ \sum_\limits{j=2}^N logP(z_j\vert z_{j-1}))\]

&lt;p&gt;相加的三项中，第一项为由标签到词的条件概率，记为$A$；第二项为标签出现在句首的概率，记为$B$，第三项为标签之间的转移概率，记为$\pi$。&lt;/p&gt;

&lt;p&gt;在有标注的数据集上，上述三项的概率能够通过统计得到。&lt;/p&gt;

&lt;p&gt;对于一条待标注的文本$S_u$，长度为$N$，其所有可能的标签序列有$n_{tag}^N$种，对所有情况可以计算概率$P(Z_i\vert S)$，取概率最大的标签序列即可。&lt;/p&gt;

&lt;p&gt;实际应用中，枚举所有种可能的效率是非常低的，因此需要使用更高效的算法来对路径进行剪枝。维特比算法是一种动态规划算法，用于多个步骤且每个步骤中有多种选择的问题的最优路径选择。维特比算法通过计算所有前序步骤到当前步骤的最小代价（或最大收益），以及当前步骤做选择时的代价（收益）来进行步骤的选择，最后，通过回溯法来选择最优路径。&lt;/p&gt;

&lt;p&gt;下面是上述过程在词性标注任务上的一种实现。&lt;/p&gt;

&lt;p&gt;训练数据的格式为：每行：词/词性&lt;/p&gt;

&lt;p&gt;实现：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_mapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; build token mapper and tag mapper &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id2tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id2word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;word_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tag_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sp_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sp_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sp_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_count&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;id2word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;word_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag_count&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;id2tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;tag_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;n_word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;word size:{}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tag size:{}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    build params of HMM: theta = (pi, A, B)
    - pi is a vector marks the probe of each tag to be the first tag
      of a sentence, size: [1, n_tag]
    - A is a matrix of condition probe of words given tags,size: [n_tag, n_word]
    - B is a matrix of transition probe between tags, size: [n_tag, n_tag]&quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# probe of starting tag
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# condition probe p(word|tag)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# transition probe p(tag_i|tag_j)
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;at_start_of_sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;last_tag_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;word_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at_start_of_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# starting prob
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# cond. prob
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;at_start_of_sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# cond. prob
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_tag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# trans. probe
&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;at_start_of_sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;last_tag_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;last_tag_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# done counting, normalize...
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;viterbi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    decode with viterbi
    :param sentence: sentence to decode
    :param pi: init probe of tag
    :param a: cond probe of words given tags
    :param b: trans probe between tags
    :return:
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# words of sentence
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;path_record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# dp
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 每个单词
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 每个词性
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e6&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;path_record&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# find best sequence
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;best_tag_sequence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;best_tag_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;best_tag_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path_record&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_tag_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;tag_sequence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id2tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_tag_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag_sequence&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;train_data_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;./resource/traindata.txt&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;The big question is whether the president will have the strength .&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 1. build mapper of words and tags
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_mapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2. \theta = (\pi, A, B), build them
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_data_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3. find optimal path with viterbi
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tag_sequence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;viterbi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# ['DT', 'JJ', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'MD', 'VB', 'DT', 'NN', '.']
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 11 May 2020 01:16:03 +0800</pubDate>
        <link>http://localhost:4000//2020/05/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E5%AE%9E%E8%B7%B5</link>
        <guid isPermaLink="true">http://localhost:4000//2020/05/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E5%AE%9E%E8%B7%B5</guid>
        
        <category>Sequence Labeling</category>
        
        <category>Machine Learning</category>
        
        
        <category>NLP</category>
        
      </item>
    
  </channel>
</rss>
