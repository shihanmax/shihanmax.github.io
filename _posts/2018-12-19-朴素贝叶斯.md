---
title:  "朴素贝叶斯"
layout: post
date:   2018-12-19 00:00:00
categories: Machine learning
tags:  ["Machine Learning", "PGM"]
syntaxHighlighter: yes
mathjax: true
---

## 一、优缺点

### 优点

- 过程简单，速度快

- 适用于多类分类，且不会造成复杂度大幅上升

- 在样本分布独立的假设下，效果很好

- 与逻辑回归相比，需要更少的样本

- 对类别型的特征变量和符合正态分布的数值型变量效果好

    <!--more-->

### 缺点

- 对训练集中没有出现的变量，概率为0（需要应用平滑技术）
- 计算出的概率不太具有解释性
- 现实情况中，样本并不总是能够满足独立这一前提假设

## 二、常见应用场景

- 文本分类/垃圾文本过滤/情感识别
- 多分类实时预测
- 推荐系统（协同过滤是强相关性，泛化能力弱，朴素贝叶斯与之结合，能够增强推荐的覆盖度和效果）

## 三、应用注意点

- 连续数值型特征，要变换成满足正态分布的形式
- 对零频项，需要做平滑
- 相关特征需要去除（高相关的特征，相当于double同一个特征的效果）
- 可调参数较少，需要关注数据预处理和特征选择
- 不适用bagging、boosting等增强方法，因为这些方法是用来减少过拟合（减少方差）的，但朴素贝叶斯没有方差可以减少。

## 四、在垃圾邮件识别中的应用

### 贝叶斯公式

$$P(Y \mid X)=\cfrac{P(X\mid Y)P(Y)}{P(X)}$$

以垃圾邮件识别为例（以H表示事件“是垃圾邮件”，N表示事件“不是垃圾邮件”）：

$$P(H\mid mail)=\cfrac{P(mail\mid H)P(H)}{P(mail)}$$

其中：

- $P(H)$称先验概率
- $P(H\mid mail)$称后验概率

假设某一封邮件的内容是“我司可办理正规发票”，该邮件是垃圾邮件的概率是：

$$P(H\mid 我司可办理正规发票)=\cfrac{P(我司可办理正规发票\mid H)P(H)}{P(我司可办理正规发票)}$$

由于邮件中包含的句子多种多样，不太可能将所有句子在正常邮件和垃圾邮件中出现的次数，考虑将句子特征转化为词的特征，上式变为：

$$P(H\mid 我\;司\;可\;办理\;正规\;发票)=\cfrac{P(我\;司\;可\;办理\;正规\;发票\mid H)P(H)}{P(我\;司\;可\;办理\;正规\;发票)}  \tag{1}$$

#### 独立性假设的引入

针对$P(我\;司\;可\;办理\;正规\;发票)$，引入“朴素”的**独立性**假设：

$$P(我\;司\;可\;办理\;正规\;发票\mid H) \approx P(我\mid H)*P(司\mid H)*P(可\mid H)*P(办理\mid H)*P(正规\mid H)*P(发票\mid H)$$

上式中的分量$P(我\mid H)$表示，垃圾邮件中，“我”出现的概率。

$$P(我\mid H)=\cfrac{P(我,H)}{P(H)} \approx \cfrac{count(我,H)}{count(H)} \tag{2}$$

令$C = P(H\mid 我\;司\;可\;办理\;正规\;发票)$，$\overline C = P(N\mid 我\;司\;可\;办理\;正规\;发票)$

判断该邮件是否是垃圾邮件，只需要比较$(1)$式中的分子即可：

即比较：

$$P(我\mid H)*P(司\mid H)*P(可\mid H)*P(办理\mid H)*P(正规\mid H)*P(发票\mid H)*P(H) \tag{3}$$

与

$$P(我\mid N)*P(司\mid N)*P(可\mid N)*P(办理\mid N)*P(正规\mid N)*P(发票\mid N)*P(N) \tag{4}$$

的大小，$(3)、(4)$式中的各项，可以通过对语料的统计，通过式$(2)$得到。

## 五、其他问题

### 5.1 重复词语的三种方式

1. 多项式模型，重复项的概率为重复项出现次数的指数次方
2. 伯努利模型，认为任何项仅出现1次
3. 混合模型，计算句子概率时，不考虑词语重复出现；而在计算词语出现的概率$P(词语 \mid H)$时，考虑词语重复

### 5.2 停用词和关键词

去掉语料中的停用词，可以减少模型训练和判断分类的时间，可以通过对照停用词表实现；而关键词相对普通的词，在训练中往往具有更大的权重，如上述例子中的“发票”。关键词需要人工经验进行指定。

### 5.3 平滑技术

在上述例子中，如果“发票”一词以前没有出现过，则计算概率时，会导致整个分子的值变为0（这种情况很常见）。

$$P(word \mid H)=\cfrac{count(word)+1}{\sum (count(word)+k)}$$

其中，$k$是邮件类别数，这里取2。

## 六、实验

待补充

## 参考

[1. 朴素贝叶斯实战与进阶](https://blog.csdn.net/han_xiaoyang/article/details/50629608)

[2. 用朴素贝叶斯进行文本分类](https://blog.csdn.net/suibianshen2012/article/details/51613759)
