## NLG review

categories

- Text-to-Text
- Data-to-Text
- Table-to-Text
- Vision-to-Text (Image caption)

我们重点关注第一个：text-to-text。



difficulties of NLG

- grammatical complexity of natural language
- difficulties during the extraction, simplification and transformation of the input information (task-specific)



applications of text-to-text NLG

- machine translation
- fusion and summarization of related sentences or texts to make them more concise
- **simplification of complex texts**
- automatic spelling, grammar and text correction
- automatic generation of peer reviews / stories / News
- generation of paraphrases of input sentences
- automatic generation of questions, for educational and other purposes



## 文本生成模型

VAE

- CVAE
- vae-seq2seq
- 多级隐变量vae
- PHVM（Planning-based Hierarchical Variational Model）

GAN based models

- SeqGAN

  suffer from two problems:

  - gradient vanishing

    when the discriminator is trained to be much stronger than the generator, it becomes extremely hard for the gen- erator to have any actual updates since any output instances of the generator will be scored as almost 0. This may cause the training stops too early before it comes to the true con- vergence or Nash Equilibrium.

  - mode collapse

    which increases the estimated probability of sampling particular to- kens earning high evaluation from the discriminator. As a re- sult, the generator only manages to mimic a limited part of the target distribution, which significantly reduces the diversity of the outputs.

- 

RL based models

CNN

- Convolutional Sequence to Sequence Learning（FAIR）



Seq2seq

- seq2seq+attention
- seq2seq copy机制
- seq2seq pointer generator networks
- seq2BF主题约束
- Mem2Seq



## 可控文本生成

A Survey of Knowledge-Enhanced Text Generation  https://www.microsoft.com/en-us/research/uploads/prod/2020/10/2010.04389.pdf





参考：

1. [Neural Text Generation: Past, Present and Beyond](https://arxiv.org/pdf/1803.07133.pdf)
2. [Survey of the State of the Art in Natural Language Generation: Core tasks, applications](https://arxiv.org/pdf/1703.09902.pdf)
3. 