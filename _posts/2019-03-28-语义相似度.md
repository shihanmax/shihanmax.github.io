---
title:  "语义相似度"
layout: post
date:   2019-03-28 00:00:00
tags:  ["Deep Learning", "Similarity"] 
categories: NLP
syntaxHighlighter: yes
mathjax: true
---

论文《APPLYING DEEP LEARNING TO ANSWER SELECTION:
A STUDY AND AN OPEN TASK》阅读笔记

文章整理并开源了首个保险领域的问答数据集，在此数据集上探讨了不同CNN架构以及不同的相似度评价方法对语义相似度模型效果的影响。

<!--more-->

# 1. 问题设定

在QA任务中，给定问题$q$和答案候选集$\{a_1, a_2, …, a_n\}$，目标是从候选集中选出最正确的答案$a_k$（如果存在）。这个问题可以转化为一个文本二分类任务：针对一个问题-答案对$\{q,a_i\}$，确定是否是一对正确的QA对，而关于"正确"，则需要一种文本距离衡量手段，经典的有cosine similarity，本文提出了两种相似度计算方案GESD和 AESD（包含超参数），并在数据集上对比了超参数不同的情况下，各种相似度计算方案的效果。

# 2. 模型架构

在训练时，使用预训练的词向量，将词向量求和作为问题$q$，候选答案$a$的表示向量。

总体思路是：首先通过CNN计算出问题$q$和答案$a$的向量表示，然后使用相似度衡量指标来计算二者之间的相似度。

本文提出了六种基于CNN的文本分类架构：

1. $q$和$a$进入独立的隐藏层和卷积层，进入pooling层后得到各自的表示向量
2. $q$和$a$进入共享的隐藏层和卷积层，进入pooling层后得到各自的表示向量
3. $q$和$a$进入共享的隐藏层和卷积层，进入pooling层后，进入独立的隐藏层，得到各自的表示向量
4. $q$和$a$进入共享的隐藏层和卷积层，进入pooling层后，进入共享的隐藏层，得到各自的表示向量
5. $q$和$a$进入共享的隐藏层和卷积层1、卷积层2，进入pooling层后得到各自的表示向量
6. $q$和$a$进入共享的隐藏层和卷积层1、卷积层2，将卷积层1的跳远连接和卷积层2求和后进入pooling层后得到各自的表示向量

# 3. 相似度计算方法汇总

1. Cosine

   $$k(x,y)=\cfrac{xy^T}{\lVert x\rVert \lVert y\rVert}$$

2. Polinomial

   $$k(x,y)=(\gamma xy^T+c)d$$

3. Sigmoid

   $$k(x,y)=tanh(\gamma xy^T+c)$$

4. RBF

   $$k(x,y)=exp(-\gamma \lVert x-y \rVert_2)$$

5. euclidean

   $$k(x,y)=\cfrac{1}{1+\lVert x-y \rVert}$$

6. exponential

   $$k(x,y)=exp(-\gamma \lVert x-y \rVert_1)$$

7. manhattan

   $$k(x,y)=\cfrac{1}{1+\lVert x-y \rVert}_1$$

8. GESD（Geometric mean of Euclidean and Sigmoid Dot product）

   $$k(x,y)=\cfrac{1}{1+\lVert x-y \rVert} \cdot \cfrac{1}{1+exp(-\gamma (xy^T+c))}$$

9. AESD（Arithmetic mean of Euclidean and Sigmoid Dot product）

   $$k(x,y)=\cfrac{0.5}{1+\lVert x-y \rVert} \cdot \cfrac{0.5}{1+exp(-\gamma (xy^T+c))}$$

# 4. 结果讨论

1. CNN模型较baseline模型有很大的提升

2. 在现有数据上，结构2的表现最优，分析原因：$q$与$a$共享卷积层能够保证抽取的特征在同一个空间中，如果不共享卷积层，在数据集有限的情况下，模型很难将两个并列的卷积层的统一；

3. 卷积层后再加一层隐藏层会降低模型的性能，卷积层已经将有用的特征抽取出来了，没有必要再将特征映射到另一个空间中

4. 增加卷积核数量可以抽取出更多的特征，对模型性能提升有明显帮助

5. 两层CNN能够对特征进行更高层次的抽象

6. 深层次的DNN训练有一定难度，加入类似于resNet中的跳远连接结构有助于缓解这个现象

7. 相似度衡量方法也很重要

   第3节中讨论的相似度计算方法大致分类三类：

   1. 基于L1范数的：semantic distance of Q and A summed from each coordinate axis
   2. 基于L2范数的：straight-line semantic distance of Q and A
   3. 基于内积的：the angle between Q and A

   我们提出的*ESD是基于L2和基于内积的结合，在模型评估中表现最好。

